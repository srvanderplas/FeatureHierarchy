\documentclass[10pt]{article}
\usepackage{geometry}                % See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   % ... or a4paper or a5paper or ... 
%\geometry{landscape}                % Activate for for rotated page geometry
%\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{natbib}
\usepackage{amsmath}
\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}

\title{Group beats Trend!? \\Testing feature hierarchy in statistical graphics}
\author{Susan VanderPlas, Heike Hofmann\thanks{Department of Statistics and Statistical Laboratory, Iowa State University}}
\begin{document}
\SweaveOpts{concordance=TRUE}
\maketitle
\begin{abstract}abstract goes here
\end{abstract}

\section{Introduction and background}
Intro to lineups \citep{Buja:2009hp, mahbub:2013, wickham:2010, Hofmann:2012ts}

The change to lineups we make is to introduce a second target to each lineup. We then keep track of how many observers choose any one of the two targets (to assess the difficulty of a lineup), and additionally we  record how often observers choose one target over the other one. This is information that we can use to evaluate how strong the signal of one target is compared to the other one. 

A further extension of this testing framework are the use of color (in a qualitative color scheme), the use of shapes, and additional density lines - we anticipate that all of these features are going to emphasize the clustering component. 
On the other hand, regression lines should emphasize any linear trends in the data.

\section{Design Choices}
Perceptual kernels \citep{heer:2014}
\section{Generating Model}
We are working with two  models $M_C$ and $M_T$ to generate data for the target plots. The null plots are showing data generate from a mixture model $M_0$. We made sure that data from the clustering model $M_C$ shares the same correlation 
with the null data, while data from model $M_T$ exhibits a similar amount of clustering as the null data. 

\subsection{Cluster Model $M_C$}
\begin{enumerate}
  \item Generate cluster centers along a line, then generate points around the cluster center. \\
  Algorithm: \\
  Parameters $N$ points, $K$ clusters, $q$ cluster cohesion
  \begin{enumerate}
    \item Generate cluster centers $(c^x_{i}, c^y_{i}), i=1, ..., K$:
      \begin{enumerate}
        \item Generate vectors $c^{x}$ and $c^y$ as permutations of $\{1, ..., K\}$, 
        \item such that the correlation between cluster centers \text{Cor}$(c^{x}, c^{y})$ falls into a range of [.25, .9].
        \newcomment{We might have to go up with the correlation a bit. I'm still worried that people will pick the cluster plot from the trend line lineup because of the lowest slope. }
      \end{enumerate}
      \item Normalize cluster centers by 
      \[
        \tilde{c}^x_{i} = \frac{c^x_{i} - \bar{c}}{s_c} \ \ \text{ and } \ \ \tilde{c}^y_{i} = \frac{c^y_{i} - \bar{c}}{s_c},
      \]
      where $\overline{c} = K(K+1)/2$ and $s_c^2 = \frac{K(K+1)(2K+1)}{6} - \frac{K^2(K+1)^2}{4}$ for all $i = 1, ..., K$.
%       \begin{enumerate}
%         \item $c_{xi} = (c_{xi} - \overline{c}_x)/sd_{c_{x}}$
%         \item $c_{yi} = (c_{yi} - \overline{c}_y)/sd_{c_{y}}$
%       \end{enumerate}
    \item Determine group size $g_i$ for groups $i = 1, ..., K$ as a random draw $g_i \sim \text{Multinomial}(K, p)$ where $p = p_1/\sum_{i=1}^K p_{1i}$ for  $p_{1i} \sim N(\frac{1}{K}, \frac{1}{2 K^2})$. 
    \item Generate points around cluster centers: 
      \begin{enumerate}
        \item $x^\ast_i = c^x_{g_i} + e$, $e_i \sim N(0, q)$
        \item $y^\ast_i = c^y_{g_i} + e$, $e_i \sim N(0, q)$
      \end{enumerate}
      It may be reasonable to draw $q$ from a distribution of some sort.
    
  \end{enumerate}
% \begin{enumerate}
%   \item Generate cluster centers along a line, then generate points around the cluster center. \\
%   Algorithm: \\
%   Parameters $N$ points, $K$ clusters, $q$ cluster cohesion, $s$ cluster std. dev.
%   \begin{enumerate}
%     \item Generate cluster centers $(c^x_i, c^y_i), i=1, ..., K$:
%       \begin{enumerate}
%         \item $c^x_i = (i-1)+e_x$, $e_x \sim Unif(-0.2, 0.2)$
%         \item $c^z \sim Unif(-q*K, q*K)$\\
%         $c^y_i = (c^z_i-\overline{c^z})/\sigma_{c^z} * q * K$
%       \end{enumerate}
%     \item Determine groups: $g \sim Multinomial(K, p)$ where $p = p_1/\sum_1^K p_{1i}$ where  $p_{1i} \sim N(\frac{1}{K}, \frac{1}{2 K^2})$ 
%     \item Generate points around cluster centers: 
%       \begin{enumerate}
%         \item $x^\ast_i = c^x_{g_i} + e$, $e_i \sim N(0, s)$
%         \item $y^\ast_i = c^y_{g_i} + e$, $e_i \sim N(0, s)$
%       \end{enumerate}
%     \item Scale points
%       \begin{enumerate}
%         \item $x_i = (x^\ast_i - \overline{x^\ast})/sd_{x^\ast}$
%         \item $y_i = (y^\ast_i - \overline{y^\ast})/sd_{y^\ast}$
%       \end{enumerate}
%   \end{enumerate}
%   Advantages:
%     \begin{enumerate}
%       \item Easy to manipulate underlying trend
%       \item Cluster variance/cohesion can be easily manipulated
%     \end{enumerate}
%   Disadvantages:
%     \begin{enumerate}
%       \item Works poorly for more than 3 groups
%       \item Difficult to easily specify cluster distribution along regression line while guaranteeing same underlying regression line
%       \item Cluster variance (away from line) doesn't show up well - not enough clusters to ensure similar overall variance compared to null plots
%     \end{enumerate}
%   \item Generate points in $K$ dimensions using random noise, then use LDA to get $K$ clusters\\
%     Advantages:
%     \begin{enumerate}
%       \item Clusters are separated in space
%       \item Variance is fairly easy to manipulate
%     \end{enumerate}
%   Disadvantages:
%     \begin{enumerate}
%       \item Difficult to translate to linear regression because of cluster distribution
%       \item Clusters are fairly easily identifiable
%     \end{enumerate}
\end{enumerate}
\subsection{Regression Model $M_T$}

\subsection{Null Model $M_0$}
The generative model for null data  is created as a mixture model $M_0$ that draws $n_c \sim B_{N, \lambda}$ observations from the cluster model, and $n_T = N - n_c$ from the regression model $M_T$.

\bibliographystyle{asa}
\bibliography{references}

\end{document}