\documentclass[10pt]{article}
\usepackage{geometry}                % See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   % ... or a4paper or a5paper or ... 
%\geometry{landscape}                % Activate for for rotated page geometry
%\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{afterpage}
\usepackage{amssymb}
\usepackage{natbib}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{color}
\usepackage{multirow}
\usepackage{rotating}
\usepackage[dvipsnames,svgnames, table]{xcolor}
\usepackage{hyperref}
\graphicspath{{figure/}}

\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}
\usepackage[colorinlistoftodos]{todonotes}
%---------------------------------------------------
%                 Editing Commands
\newcommand{\done}[2][inline]{\todo[color=SpringGreen, #1]{#2}}  % for todos that have been seen and dealt with
\newcommand{\meh}[2][inline]{\todo[color=White, #1]{#2}}   % for todos that may no longer be relevant 
\newcommand{\comment}[2][inline]{\todo[color=SkyBlue, #1]{#2}} % for comments that may not be "to-do"s
%\newcommand{\mcomment}[1]{\todo[color=SkyBlue]{#1}} % for margin comments
\newcommand{\newtext}[1]{\todo[inline, color=White]{ \color{OliveGreen}{#1}}} % new text - not necessarily something to be done
\newcommand{\newdo}[1]{\todo[inline, color=Lime]{#1}} % new to do item
%
%---------------------------------------------------
%                 Placing Figures


%---------------------------------------------------
% Define new environment
\newtheorem{theorem}{Theorem}[section]
\newtheorem{algorithm}[theorem]{Algorithm}
%---------------------------------------------------

\title{Group beats Trend!? \\Testing feature hierarchy in statistical graphics}
\author{Susan VanderPlas, Heike Hofmann\thanks{Department of Statistics and Statistical Laboratory, Iowa State University}}
\begin{document}
\maketitle
\begin{abstract}abstract goes here
\end{abstract}
<<setup, fig.keep='all', cache=FALSE, echo=FALSE, eval=TRUE, include=FALSE>>=
rm(list=ls())
options(replace.assign=TRUE,width=70)
require(knitr)
opts_chunk$set(fig.path='figure/', cache.path='cache/', fig.align='center', fig.width=5, fig.height=5, par=TRUE, cache=TRUE, concordance=TRUE, autodep=TRUE, message=F, warning=F)

library(stringr)
library(lubridate)

library(reshape2)
library(plyr)
library(dplyr)
library(magrittr)

library(ggplot2)
library(grid)
suppressMessages(library(gridExtra))
library(RColorBrewer)

library(nullabor)
library(digest)
library(Cairo)

library(lme4)

library(xtable)

source("../../Code/MixtureLineups.R")
source("../../Code/theme_lineup.R")
@

\tableofcontents
\newpage
\section{Introduction and background}
\comment{Discussion of pre-attentive visual features \citep{healey2012attention} - with a focus on hierarchy of pre-attentive features: color trumps shape - do we also see this in our results, and if so, by how much?}


Numerical information can be difficult to communicate effectively in raw form, due to limits on attention span, short term memory, and information storage mechanisms within the human brain. 
Graphics are much more effective for communicating numerical information, as (well-designed) graphics order the numerical information spatially and utilize the higher-bandwidth visual system. 
Visual data displays serve as a form of external cognition \ref{zhang1997nature,scaife1996external}, ordering and visually summarizing data which would be hopelessly confusing in tabular format. 
One fantastic example of this phenomenon is the Hertzsprung-Russell (HR) diagram, which was described as ``one of the greatest observational syntheses in astronomy and astrophysics" because it allowed astronomers to clearly relate the absolute magnitude of a star to its' spectral classification; facilitating greater understanding of stellar evolution \citep{spence1993remarkable}. 
The data it displayed was previously available in several different tables; when plotted on the same chart, information that was invisible in a tabular representation became immediately clear \citep{lewandowsky1989perception}. 
Graphical displays more efficiently utilize cognitive resources by reducing the burden of storing, ordering, and summarizing raw data; this frees bandwidth for higher levels of information synthesis, allowing observers to note outliers, understand relationships between variables, and form new hypotheses.



Graphical displays are powerful because they efficiently and effectively convey numerical information, but there exists  relatively sparse empirical information about how the human perceptual system processes these displays. Our understanding of the perception of statistical graphics is informed by general psychological and psychophysics research as well as more specific research into the perception of data displays \citep{cleveland:1984}. 



One relevant focus of psychological research is pre-attentive perception, that is, perception which occurs automatically in the first 200 ms of exposure to a visual stimulus \citep{treisman1985preattentive}. 

Research into preattentive perception provides us with some information about the temporal hierarchy of graphical feature processing. Color, line orientation, and shape are processed preattentively; that is, within 200 ms, it is possible to identify a single target in a field of distractors, if the target differs with respect to color or shape \citep{goldstein2009encyclopedia}. 
Research by \citet{healey1999large} extends this work, demonstrating that certain features of three-dimensional data displays are also processed preattentively. However, neither target identification nor three-dimensional data processing always translate into faster or more accurate inference about the data displayed, particularly when participants have to integrate several preattentive features to understand the data. 


Feature detection at the attentive stage of perception has also been examined in the context of statistical graphics; researchers have evaluated the perceptual implications of utilizing color, fill, shapes, and letters to denote categorical or stratified data in scatterplots. \citet{cleveland:1984} ranked the optimality of these plot aesthetics based on response accuracy, preferring colors, amount of fill, shapes, and finally letters to indicate category membership. \citet{lewandowsky1989discriminating} examined both accuracy and response time, finding that color is faster and more accurately perceived (except by individuals with color deficiency). Shape, fill, and discriminable letters (letters which do not share visual features, such as HQX) were identified as less accurate than color, while confusable letters (such as HEF) result in significantly decreased accuracy. 


Another area of psychological research, Gestalt psychology, examines perception as a holistic experience, establishing and evaluating mental heuristics used to transform visual stimuli into useful, coherent information. 
Gestalt rules of perception can be easily applied to statistical graphics, as they describe the way we organize visual input, focusing on the holistic experience rather than the individual perceptual features. 

For example, rather than perceiving four legs, a tail, two eyes, two ears, and a nose, we perceive a dog. The rules of perceptual grouping or organization, as stated in \citet{goldstein2009encyclopedia} are:
\begin{itemize}
\item Proximity: two elements which are close together are more likely to belong to a single unit.
\item Similarity: the more similar two elements are, the more likely they belong to a single unit.
\item Common fate: two elements moving together likely belong to a single unit.
\item Good continuation: two elements which blend together smoothly likely belong to one unit.
\item Closure: elements which can be assembled into closed or convex objects likely belong together. 
\item Common region: elements contained within a common region likely belong together. 
\item Connectedness: elements physically connected to each other are more likely to belong together.
\end{itemize}

\begin{figure}
<<gestalt1, echo =FALSE, out.width='0.32\\textwidth', fig.width=3, fig.height=3, fig.show='hold'>>=
x1 <- rnorm(25, mean=4, sd=0.5)
x2 <- rnorm(25, mean=0, sd=0.5)
y1 <- rnorm(25, mean=1, sd=0.5)
y2 <- rnorm(25, mean=2, sd=0.5)
qplot(c(x1,x2), c(y1,y2)) + theme_bw() + xlab("x") + ylab("y")

x <- rnorm(60)
y <- rnorm(60)
group <- rep(1:4, length=60)
qplot(x,y, color=factor(group%/%2), shape=factor(group%/%2)) + theme_bw() + xlab("x") + ylab("y") + scale_color_brewer(palette="Set1") + theme(legend.position="none")

x1 <- runif(50,-.75,1.25)
y1 <- x1^2 - x1 + rnorm(50, sd=0.1)
x2 <- runif(25,-.75,1.25)
y2 <- x2 + rnorm(25, sd=0.1)

qplot(c(x1,x2),c(y1,y2)) + theme_bw() + xlab("x") + ylab("y") 
@
\caption{\label{fig:gestalt} \emph{Proximity} renders the fifty points of the first scatterplot as two distinct (and equal-sized) groups. Shapes and colors create different groups of points in the middle scatterplot, invoking the Gestalt principle of \emph{Similarity}. \emph{Good Continuation} renders the points in the scatterplot on the right hand side into two groups of points on curves: one a straight line with an upward slope, the other a curve that initially decreases and at the end of the range shows an uptick.} 
\end{figure}

The plots in figure \ref{fig:gestalt} demonstrate several of the gestalt principles which combine to order our perceptual experience from the top down. These laws help to order our perception of charts as well: points which are colored or shaped the same are perceived as belonging to a group (similarity), points within a bounding interval or ellipse are perceived as belonging to the same group (common region), and regression lines with confidence intervals are perceived as single units (connectedness, closure, and/or common region). 
\newdo{clarify next sentence}
The use of physical location, color, and shape to organize graphical units mentally utilizes both preattentive processing and higher-order gestalt schemas, identifying and grouping similar graphical features and simultaneously directing attention to graphical features which stand alone. 

Research on preattentive perception is important because features that are perceived preattentively do not require as much mental effort to process from raw visual stimuli; theoretically, subsequent top-down gestalt heuristics can be applied to such stimuli more quickly. 

% \comment{We should also look at the time to response -- it would be interesting, to see if the conflicting stimuli need more time to come to a decision. It's obviously not milliseconds that we measure, but it might still be informative. (We would need to exclude everybody's first attempt). }

% \comment{This study - introduce the fact first, that this paper will include a user study.}
This paper describes the results of a user study designed to explore the hierarchy of gestalt principles in perception of statistical graphics. We utilize information from previous studies \citep{heer:2014, robinson:03} concerning the hierarchy of preattentive feature perception in order to maximize the effect of preattentive feature differences. 

%\comment{might be useful to have a small diagram describing the perceptual process (with preattentive processing way at the top and gestalt heuristic processing in the middle, with "cognitive effort" at the bottom). Not sure if it's necessary, though. HH: good idea, let's see how much space we'll have. }

Statistical graphics can be difficult to examine experimentally; qualitative studies rely on descriptions of the plot by participants who may not be able to articulate their observations precisely, while quantitative studies may only be able to examine whether the viewer can accurately read numerical information from the chart, instead of exploring the overall utility of the data display holistically. Statistical lineups, described in the next section, are an important experimental tool for evaluating the perceptual utility of graphical displays. Lineups fuse commonly used psychological tests (target identification, visual search) \newtext{XXX cite the ACM Transact submission here} with statistical hypothesis tests to facilitate formal experimental evaluation of statistical graphics. 


\subsection*{Statistical Lineups}
% 
% \todo[inline]{Intro to lineups \citep{Buja:2009hp, mahbub:2013, wickham:2010, Hofmann:2012ts}.}
% \comment{Describe the lineup protocol, including basic statistics. Link to the psychological "target and distractors" approach, which can be used to justify the addition of a second target, even with the PITA of the statistical complications. }
%\newdo{Add basic statistics?}

Lineups are an experimental tool designed to serve as a visual hypothesis test, separating ``significant" visual effects from those that would be expected under a null hypothesis \citep{buja2009statistical, majumder2013validation,hofmann2012graphical, wickham2010graphical}. 
A statistical lineup consists of (usually) 20 sub-plots, arranged in a grid (examples are shown in figure \ref{fig:plotExamples}). 
Of these plots, one plot is the ``target plot'', generated from either real data or an alternate model (equivalent to $H_A$ in hypothesis testing); the other 19 plots are generated either using bootstrap samples of the real data or by generating ``true null" plots from the null distribution $H_0$. 
If participants can identify the target plot from the field of distractors, then the visual display is deemed significant in the same sense that a numerical test with $p<0.05$ is significant. 



Apart from the hypothesis testing construct, the use of statistical lineups to test statistical graphics conforms nicely to psychological testing constructs such as visual search \citep{demita1981validity,treisman1980feature}, where a single target is embedded in a field of distractors and response time, accuracy, or both are used to measure the complexity of the underlying psychological processes leading to identification. 


In this study, we modify the lineup protocol by introducing a second target to each lineup. The two targets represent two different, competing signals; the participant's choice then demonstrates empirically which signal is more salient. 
If both targets exhibit similar signal, participants may identify both targets, removing any forced-choice scenario which might skew results (few participants exercised this option). 

By tracking the proportion of observers choosing either target plot (a measure of overall lineup difficulty) as well as which proportion of observers choose one target over the other target, we can determine the relative strength of the two competing signals amid a field of distractors. At this level, signal strength is determined by the experimental data and the generating model; we are measuring the ``power" (in a statistical sense) of the human perceptual system, rather than raw numerical signal. 

Using this testing framework, we  apply different aesthetics, such as color and shape, as well as plot objects which display statistical calculations, such as trend lines and bounding ellipses. These additional plot layers, discussed in more detail in the next section, are designed to emphasize one of the two competing targets and affect the overall visual signal of the target plot relative to the null plots. We expect that in a situation similar to the third plot of figure \ref{fig:gestalt}, the addition of two trend lines would emphasize the ``good continuation" of points in the plot, producing a stronger visual signal, even though the underlying data has not changed. Similarly, the grouping effect in the first plot in the figure would be enhanced if the points in each group were colored differently, as the proximity heuristic would be supplemented by similarity. In plots that are ambiguous, containing some clustering of points as well as a linear relationship between $x$ and $y$, additional aesthetic cues may ``tip the balance" in favor of recognizing one type of signal.

% A further extension of this testing framework are the use of color (in a qualitative color scheme), the use of shapes, and additional density lines - we anticipate that all of these features are going to emphasize the clustering component. 
% On the other hand, regression lines should emphasize any linear trends in the data.

This study is designed to inform our understanding of the perceptual implications of these additional aesthetics, in order to provide guidelines for the creation of data displays which provide visual cues consistent with gestalt heuristics and preattentive perceptual preferences. %awesome alliteration, right? HH: :)

The next section discusses the particulars of the experimental design, including the data generation model, plot aesthetics, selection of color and shape palettes, and other important considerations. Experimental results are presented in section \ref{sec:Results}, and implications and conclusions are discussed in section \ref{sec:Conclusion}. 

\section{Experimental Setup and Design} \label{sec:ExperimentalDesign}

In this section, we discuss the generating data models for the two types of signal plots and the null plots, the selection of plot aesthetic combinations and aesthetic values, and the design and execution of the experiment.


%\comment{I know this will have to be rearranged, expanded, and transitions between sections will need to be added, but I want to get the paragraphs out.}

\subsection{Data Generation}

Lineups require a single ``target" data set (which we are expanding to two competing ``target" data sets), and a method for generating null plots. When utilizing real data for target plots, null plots are often generated through permutations. % bootstrap sampling, but this introduces some dependencies between target and null plots which complicate the statistical analysis of the results.

%\newdo{add citations}

Here, it is possible to generate true null plots, which are generated from the null model and do not depend on the data used in the target plot. 
This experiment will measure two competing gestalt heuristics, proximity and good continuation, using two data-generating models: $M_C$, which generates data with $K$ clusters, and $M_T$, which generates data with a positive correlation between $x$ and $y$. 
True null datasets are created using a mixture model $M_0$ which combines $M_C$ and $M_T$. Both $M_C$ and $M_T$ generate data in the same range of values. 
Additionally, $M_C$ generates clustered data with linear correlations that are within $\rho = (0.25, 0.75)$, similar to the linear relationship between datasets generated by $M_0$, and $M_T$ generates data with clustering similar to $M_0$. These constraints provide some assurance that participants who select a plot with data generated from $M_T$ are doing so because of visual cues indicating a linear trend (rather than a lack of clustering compared to plots with data generated from $M_0$), and participants who select a plot with data generated from $M_C$ are doing so because of visual cues indicating clustering, rather than a lack of a linear relationship relative to plots with data generated from $M_0$. 


\subsubsection{Regression Model $M_T$}

This model has the parameter $\sigma_T$ to reflect the amount of scatter around the trend line. It generates $N$ points $(x_i, y_i), i=1, ..., N$ where $x$ and $y$ have a positive linear relationship. The data generation mechanism is as follows: 

\begin{algorithm}\hfill\newline
  Input Parameters: sample size $N$, $\sigma_T$ standard deviation around the line \\
  Output: $N$ points, in form of vectors $x$ and $y$.
  \begin{enumerate}
    \item Generate $\tilde{x}_i$, $i=1, ..., N$, as a sequence of evenly spaced points from $[-1, 1]$. 
    \item Jitter $\tilde{x}_i$ by adding small uniformly distributed perturbations to each of the values: $x_i = \tilde{x}_i + \eta_i$, where $\eta_i \sim \text{Unif}(-z, z)$, $z = \frac{2}{5(N-1)}$.
    \item Generate $y_i$ as a linear regressand of $x_i$: $y_i = x_i + e_i$, $e_i \sim N(0, \sigma^2_T)$.
    \item Center and scale $x_i$, $y_i$.
  \end{enumerate}
\end{algorithm}

We compute the coefficient of determination for all of the plots to assess the amount of linearity in each panel, computed as 
\begin{equation}\label{eq:linearMeasure}
R^2 = 1 - \frac{RSS}{TSS},
\end{equation}
where TSS is the total sum of squares, $TSS = \sum_{i=1}^N \left(y_i - \bar{y}\right)^2$ and $RSS = \sum_{i=1}^N e_i^2$, the residual sum of squares.
The expected value of the coefficient of determination $E\left[R^2\right]$ in this scenario is 
\[
E\left[R^2\right] =  \frac{1}{1 + 3\sigma^2_T},
\]
because
$E[RSS] = N\sigma^2_T$ and $E[TSS] = \sum_{i=1}^N E\left[y_i^2\right]$  (as $E[Y] = 0$), where 
$$
E\left[y_i^2\right] = E\left[x_i^2 + e_i^2 + 2 x_ie_i\right] = \frac{1}{3} + \sigma^2_T. 
$$
The use of $R^2$ to assess the strength of the linear relationship (rather than the correlation) is indicated because human perception of correlation strength more closely aligns with $R^2$ \citep{bobko1979perception,lewandowsky1989perception}. 

\begin{figure}[ht]
<<trends, fig.width=8, fig.height=3, out.width='\\textwidth', echo=FALSE>>=
sd <- c(0.1, 0.2, 0.3, 0.4)
res <- ldply(sd, function(x) { data.frame(sd.trend=x, sim.line(N=45, sd.trend=x)) })
res$label <- paste("sigma[T] :",res$sd.trend)
qplot(x,y, data=res, pch=I(1)) + facet_grid(facets=.~label, labeller="label_parsed") + theme_bw() + 
  theme(plot.margin=unit(c(0,0,0,0), "cm"))
@
\caption{\label{fig:trends} Set of scatterplots showing one draw each from the trend model $M_T$ for parameter values of  $\sigma_T \in \{0.1, 0.2, 0.3, 0.4\}$.}
\end{figure}

\subsubsection{Cluster Model $M_C$} 
We begin by generating $K$ cluster centers on a $K \times K$ grid, then we generate points around selected cluster centers. 
\begin{algorithm}\hfill\newline
  Input Parameters:  $N$ points, $K$ clusters, $\sigma_C$ cluster standard deviation \\
  Output: $N$ points, in form of vectors $x$ and $y$. 
  \begin{enumerate}
    \item Generate cluster centers $(c^x_{i}, c^y_{i})$ for each of the $K$ clusters, $i=1, ..., K$:
      \begin{enumerate}
        \item in form of two vectors $c^{x}$ and $c^y$ of permutations of $\{1, ..., K\}$, such that
        \item the correlation between cluster centers \text{cor}$(c^{x}, c^{y})$ falls into a range of $[.25, .75]$.
      \end{enumerate}
      \item Center and standardize cluster centers $(c^x, c^y)$:  
      \[
        \tilde{c}^x_{i} = \frac{c^x_{i} - \bar{c}}{s_c} \ \ \text{ and } \ \ \tilde{c}^y_{i} = \frac{c^y_{i} - \bar{c}}{s_c},
      \]
      where $\overline{c} = (K+1)/2$ and $s_c^2 = \frac{K(K+1)}{12}$ for all $i = 1, ..., K$.
    \item For the $K$ clusters, we want to have nearly equal sized groups, but allow some variability. Group sizes  $g = (g_1, ..., g_K)$ with $N = \sum_{i=1}^K g_i$, for clusters $1, ..., K$ are therefore determined as a draw from a multinomial distribution: 
    \[
    g \sim \text{Multinomial }(K, p) \text{ where } p = \tilde{p}/\sum_{i=1}^K \tilde{p}_i, \text{ for } \tilde{p} \sim N \left(\frac{1}{K}, \frac{1}{2 K^2} \right).
    \]
     
    \item Generate points around cluster centers by adding small normal perturbations: 
      \begin{eqnarray*}
        x_i &=& \tilde{c}^x_{g_i} + e^x_i, \text{ where } e^x_i \sim N(0, \sigma^2_C),\\
        y_i &=& \tilde{c}^y_{g_i} + e^y_i, \text{ where } e^y_i \sim N(0, \sigma^2_C).
      \end{eqnarray*}
    \item Center and scale $x_i$, $y_i$.
  \end{enumerate}
\end{algorithm} 


As a measure of clustering we use a coefficient to assess the amount of variability within groups, compared to total variability. Note that for the purpose of clustering, variability is measured as the variability in both $x$ and $y$ from a common mean, i.e.\ we implicitly assume that the values in $x$ and $y$ are on the same scale (which we achieve by scaling in the final step of the generation algorithm).

For two numeric variables $x$ and $y$ and grouping variable $g$ with $g_i \in \{1, ..., K\}, i = 1, ..., n$, we compute the  {\it cluster index} as follows: let $j(i)$ be the function that maps index $i = 1, ..., n$ to one of the clusters $1, ..., K$ given by the grouping variable $g$. Then for each  level of $g$, we find  a cluster center as $\bar{x}_{j(i)}$ and  $\bar{y}_{j(i)}$, and we determine the strength of the clustering by comparing the within cluster variability with the overall variability: 

\begin{eqnarray}\label{eq:clusterMeasure}
\gamma^2 &=& 1 - \frac{CSS}{TSS},\\
\nonumber CSS &=& \sum_{i=1}^n \left(x_{j(i)} - \overline{x}_{j(i)}\right)^2 + \left(y_{j(i)} - \overline{y}_{j(i)} \right)^2, \\
\nonumber TSS &=& \sum_{i=1}^n \left(x_i - \bar{x}\right)^2 + \left(y_i - \bar{y}\right)^2.
\end{eqnarray}

\begin{figure}[ht]
<<cluster, fig.width=8, fig.height=4.5, out.width='\\textwidth', echo=FALSE,dependson='setup'>>=
sd <- c(0.15, 0.2, 0.25, 0.3)
colors <-  c("#1f77b4", "#ff7f0e", "#2ca02c", "#d62728", "#9467bd", 
             "#8c564b", "#e377c2", "#7f7f7f", "#bcbd22", "#17becf")
shapes <- c(1,0,3,4,8,5,2,6,-0x25C1, -0x25B7)

colortm <- read.csv("../..//Data/color-perceptual-kernel.csv")
# colortm[3,4] <- 0
# colortm[4,3] <- 0
colortm[8,] <- 0
colortm[,8] <- 0

shapetm <- read.csv("../../Data/shape-perceptual-kernel.csv")
# shapetm[9:10,] <- 0
# shapetm[, 9:10] <- 0
shapetm[9,] <- 0
shapetm[,9] <- 0
shapetm[10,] <- 0
shapetm[,10] <- 0

color3pal <- best.combo(3, colors, colortm)
color5pal <- best.combo(5, colors, colortm)
shape3pal <- best.combo(3, shapes, shapetm)
shape5pal <- best.combo(5, shapes, shapetm)

res <- ldply(sd, function(x) { set.seed(325098573); data.frame(sd.cluster=x, sim.clusters(K=3, N=45, sd.cluster=x)) })
res$K <- 3
res$color <- color3pal[res$group]
res$shape <- shape3pal[res$group]
res2 <- ldply(sd, function(x) { set.seed(325098573); data.frame(sd.cluster=x, sim.clusters(K=5, N=75, sd.cluster=x)) })
res2$K <- 5
res2$color <- color5pal[res2$group]
res2$shape <- shape5pal[res2$group]
res <- rbind(res, res2)
suppressMessages(library(ggplot2))
res$label <- paste("sigma[C] :",res$sd.cluster)
res$Klabel <- paste("K :",res$K)
ggplot(aes(x=x, y=y, color=color, shape=shape), data=res) + 
  geom_point() + 
  facet_grid(facets=Klabel~label, labeller="label_parsed") + theme_bw() + 
  theme(plot.margin=unit(c(0,0,0,0), "cm"), legend.position="none") + 
  scale_shape_identity() + scale_color_identity() + theme(aspect.ratio=1)
@
\caption{\label{fig:clusters} Scatterplots of clustering output for different inner cluster spread $\sigma_C$  (left to right) and different number of clusters $K$ (top and bottom), generated using the same random seed at each parameter setting. The colors and shapes shown are those used in the lineups for $K=3$ and $K=5$.}
% \comment{Could you include the same colors and shapes as in our lineups?}}
\end{figure}

%\comment{For the study we used $a=1$, right?\\Susan: Yes, and I thought I'd purged all $a$ from the description accordingly, but I see that I missed one. It's fixed now. }
\subsubsection{Null Model $M_0$}
The generative model for null data is a mixture model $M_0$ that draws $n_c \sim \text{Binomial}(N, \lambda)$ observations from the cluster model, and $n_T = N - n_c$ from the regression model $M_T$. Observations are assigned groups using hierarchical clustering, which creates groups consistent with any structure present in the generated data. This provides a plausible grouping for use in aesthetic and statistics requiring categorical data (color, shape, bounding ellipses). 

\begin{figure}[ht]
<<lambda, fig.width=8, fig.height=3.5, out.width='\\textwidth', echo=FALSE>>=
lambda <- c(0, .25, .5, .75, 1)
colors <-  c("#1f77b4", "#ff7f0e", "#2ca02c", "#d62728", "#9467bd", 
             "#8c564b", "#e377c2", "#7f7f7f", "#bcbd22", "#17becf")

res <- ldply(lambda, function(x) { data.frame(lambda=x, {set.seed(325098573); mixture.sim(x, K=3, N=45, sd.trend=.25, sd.cluster=.25)}) })
res$K <- 3
res$color <- color3pal[res$group]
res$shape <- shape3pal[res$group]
res2 <- ldply(lambda, function(x) { data.frame(lambda=x, {set.seed(325098573); mixture.sim(x, K=5, N=75, sd.trend=.25, sd.cluster=.2)}) })
res2$K <- 5
res2$color <- color5pal[res2$group]
res2$shape <- shape5pal[res2$group]
res <- rbind(res, res2)
res$label <- paste("lambda :",res$lambda)
res$Klabel <- paste("K :",res$K)
ggplot(aes(x=x, y=y, color=color, shape=shape), data=res) + 
  geom_point() + 
  facet_grid(facets=Klabel~label, labeller="label_parsed") + theme_bw() + 
  theme(plot.margin=unit(c(0,0,0,0), "cm"), legend.position="none") + 
  scale_shape_identity() + scale_color_identity() + theme(aspect.ratio=1)
@
\caption{\label{fig:lambda} Scatterplots of data generated from $M_0$ using different values of $\lambda$, generated using the same random seed at each $\lambda$ value.}
\end{figure}
Null data in this experiment is generated using $\lambda = 0.5$, that is, each point in a null data set is equally likely to have been generated from $M_C$ and $M_T$. 

\subsubsection{Parameters used in Data Generation}
These models provide the foundation for this experiment; by manipulating cluster standard deviation $\sigma_C$ and regression standard deviation $\sigma_T$ (directly related to correlation strength) for varying numbers of clusters $K=3, 5$, we can systematically control the statistical signal present in the target plots and generate corresponding null plots that are mixtures of the two distributions. For each parameter set $\{K, N, \sigma_C, \sigma_T\}$, as described in table \ref{tab:parameters}, we  generate a lineup dataset consisting of one set drawn from $M_C$, one set drawn from $M_T$, and 18 sets drawn from $M_0$. 
\begin{table}[h]
  \rowcolors{2}{gray!25}{white}
\begin{center}
\begin{tabular}{lll}
\bf Parameter & \bf Description & \bf Choices\\\hline
$K$ & \# Clusters &  \begin{tabular}{l}3, 5 \end{tabular} \\
$N$ & \# Points &  \begin{tabular}{l}$15\cdot K$\end{tabular} \\
$\sigma_T$ & Scatter around trend line &   \begin{tabular}{l}.15, .25, .35  \end{tabular}\\
$\sigma_C$ & Scatter around cluster centers & \begin{tabular}{ll} .15, .20, .25 ($K=3$)\\ .20, .25, .30 ($K=5$) \end{tabular}
\\\hline
\end{tabular}
\end{center}
\caption{Parameter settings for generation of lineup datasets. \label{tab:parameters}}
\end{table}

The parameter values were chosen after examining the full parameter space through simulation of 1000 lineup datasets for each combination of $\sigma_T\in\{0.2, 0.25, ..., 0.5\}$, $\sigma_C\in\{0.1, 0.15, ..., 0.4\}$, and $K\in\{3,5\}$; 
for each data set generated, the previously described statistics for  trend  and cluster strength were computed. We compared the statistics for the relevant target plot to the most extreme value for the 18 null plots. % - for instance, the trend target plot $R^2$ value was compared to the maximum $R^2$ value in the 18 null plots. 

These distributions allow us to objectively assess the difficulty of detecting the target datasets computationally (without relying on human perception). This approach is similar to that taken in \citet{niladri:2014}.

Figure~\ref{fig:targetsignal-0} shows  densities of each measure computed from the  maximum of 18 null plots compared to  the measure in the signal plot.
There is some overlap in the distribution of $R^2$ for the null plots compared to the target plot displaying data drawn from $M_T$. 

The distribution of the cluster statistic values are more easily separated from the null plots than the distribution of the line statistic, indicating that $\sigma_C = 0.20$ is producing target plots that are a bit easier to spot than trend targets with a parameter value of $\sigma_T = 0.25$.


\begin{figure}[h]
\centering
<<null-distribution-1, echo=FALSE, cache=T, fig.width=8, fig.height=3>>=
source("../../Code/MixtureLineups.R")
sT = 0.25
sC = 0.20
N = 45
K = 3
M = 1000

if (file.exists("./figure/nulldist.Rdata")) {
  load("./figure/nulldist.Rdata")
} else {
#   nulldist<- function(N, sT=0.25, sC=0.2) {
#     nulls <- data.frame(t(replicate(N, {
#       lp <- data.frame(t(replicate(18, {
#         mix = mixture.sim(lambda=0.5, K=3, N=45, sd.cluster=sC, sd.trend=sT)
#         reg <- lm(y~x, data=mix)
#         
#   c(fline=summary(reg)$r.squared, fgroup=cluster(mix))
#   })))
#     c(fline=max(lp$fline), fgroup=max(lp$fgroup))
#   })))
#   
#   trends <- replicate(10, {
#     mix = mixture.sim(lambda=0, K=3, N=45, sd.cluster=sC, sd.trend=sT)
#     reg <- lm(y~x, data=mix)
#     c(fline=summary(reg)$r.squared)
#   })
#   
#   clusters <- replicate(10, {
#     mix = mixture.sim(lambda=1, K=3, N=45, sd.cluster=sC, sd.trend=sT)
#     clust <- lm(y~factor(group) + 0, data=mix)
#     res <- summary(aov(clust))
#     c(fgroup=cluster(mix))
#   })
#   
#   list(nulls=nulls, trends=trends, clusters=clusters)
# }
# 
# res <- nulldist(N=N, sC=sC, sT=sT)
  library(compiler)
  tmp <- function(M=1000, N=45, K=3, sT=0.3, sC=0.25) {
    data.frame(
      t(
        replicate(M, 
                  {
                    input.pars <- list(N=N, K=K, sd.trend=sT, sd.cluster=sC)
                    c(unlist(input.pars), eval.data(gen.data(input.pars)))
                    }
                  )
        )
      )
    }
  nulldist <- cmpfun(tmp)
  
  res <- nulldist(M=M, N=45, K=3, sT=sT, sC=sC)
  
  save(res, file="./figure/nulldist.Rdata")
}

# require(ggplot2)
# qplot(fline, data=res$nulls, binwidth=0.02, fill=I("gray70"), color=I("gray20")) + geom_vline(aes(xintercept=res$trends), color="black") + theme_bw() + xlab("Max(18) Distribution of Cluster Measure under Null Model")
# ggsave("figure/fline.pdf", width=8, height=4)
# qplot(fgroup, data=res$nulls, binwidth=0.01, fill=I("gray70"), color=I("gray20")) + geom_vline(aes(xintercept=res$clusters), color="black") + theme_bw() + xlab("Max(18) Distribution of Trend Measure under Null Model")
# ggsave("figure/fgroup.pdf", width=8, height=4)

longres <- melt(res, id.vars=1:4, variable.name="type", value.name = "value")
longres$dist <- c("Data", "Most Extreme of\n18 Null Dists")[1+grepl("null", longres$type)]
longres$type <- gsub("null.", "", longres$type, fixed=T)
longres$Statistic <- longres$type
longres$Statistic[longres$type=="cluster"] <- "Cluster Measure"
longres$Statistic[longres$type=="line"] <- "R squared"
longres$Statistic[longres$type=="gini"] <- "Gini Impurity"
longres$Statistic <- factor(longres$Statistic, levels=c("R squared", "Cluster Measure", "Gini Impurity"))

qplot(data=subset(longres, Statistic != "Gini Impurity"), x=value, y=..density.., stat="density", color=dist, fill=dist, geom="area", alpha=I(.5), 
    #  main=expression(paste("Simulation Results " , group("(", list(K==3, sigma[T]==.25, sigma[C]==.2), ")"))), 
      xlab="Simulated Distribution of Test Statistic", 
      ylab="Density", 
      position="identity") + 
  facet_grid(.~Statistic, scales="free", labeller=label_both) + 
  scale_color_manual("Distribution", values=c("black",  "gray")) + 
  scale_fill_manual("Distribution", values=c("transparent", "gray")) +  
  theme_bw()
@
\caption{\label{fig:targetsignal-0}Density of test statistics measuring trend strength and cluster strength for target distributions and null plots based on 1,000 draws of lineup data with $\sigma_T= 0.25, \sigma_C=0.20$ and $K=3$. }
\end{figure}
\afterpage{\clearpage}
These evaluations provide an estimate of the difficulty of identifying the target plot numerically; a target plot with $R^2=0.95$ is very easy to identify when surrounded by null plots with $R^2=0.5$, while null plots with $R^2=0.9$ make the target plot more difficult to identify. Graphical summaries of simulation results for a whole range of values for $\sigma_C$ and $\sigma_T$ are provided in appendix \ref{app:parametersimulation}.

% \comment{I want even more details: how did you get the results?}
Using information from the simulation, we identified values of $\sigma_T$ and $\sigma_C$ corresponding to ``easy", ``medium" and ``hard" numerical comparisons between corresponding target data sets and null data sets. It is important to note that the numerical measures we have described in equations \eqref{eq:linearMeasure} and \eqref{eq:clusterMeasure} only provide information on the numerical discriminability of the target datasets from the null datasets; the simulation cannot provide us with information on the perceptual discriminability, and it has been established that human perception of scatterplots does not replicate statistical measures exactly \citep{bobko1979perception, mosteller1981eye, lewandowsky1989perception}.

Each of the generated datasets is then plotted as a lineup, where we apply aesthetics which emphasize clusters and/or linear relationships, to experimentally determine how these aesthetics change participants' ability to identify each target plot. The next section describes the aesthetic combinations and their anticipated effect on participant responses. 

\subsection{Lineup Rendering}
\subsubsection{Plot Aesthetics}
Gestalt perceptual theory suggests that perceptual features such as shape, color, trend lines, and boundary regions modify the perception of ambiguous graphs, emphasizing clustering in the data (in the case of shape, color, and bounding ellipses) or linear relationships (in the case of trend lines and prediction intervals), as demonstrated in figure \ref{fig:gestalt}. For each dataset we examine the effect of plot aesthetics (color, shape) and statistical layers (trend line, boundary ellipses, prediction intervals) shown in table \ref{tab:plotaesthetics}  on target identification. Examples of these plot aesthetics are shown in figure \ref{fig:plotExamples}.

\begin{figure}[ht]
% <<samplepics, eval=T, echo=F, fig.width=6, fig.height=6, out.width=".3\\linewidth", fig.show='hold', fig.align='center', warning=FALSE, message=FALSE, results='hide'>>=
% 
% load("figure/lineupex/data.Rdata")
% d_ply(data, .(set), function(df){
%   i <- unique(df$set)
%   for(j in 1:nrow(plot.parms)){
%     p = gen.plot(df, get.aes(plot.parms[j,]), get.stats(plot.parms[j,]))
%      p <- p + theme(plot.margin=unit(c(0,0,0,0), "cm"))
%     print(p)
%   }
% })
% @

\centering
\begin{subfigure}[t]{0.28\textwidth}
  \caption{Plain}
  \includegraphics[width=\textwidth]{figure/samplepics-1}
\end{subfigure}
\begin{subfigure}[t]{0.28\textwidth}
  \caption{Color}
  \includegraphics[width=\textwidth]{figure/samplepics-2}
\end{subfigure}
\begin{subfigure}[t]{0.28\textwidth}
  \caption{Shape}
  \includegraphics[width=\textwidth]{figure/samplepics-3}
\end{subfigure}
\begin{subfigure}[t]{0.28\textwidth}
  \caption{Shape + Color}
  \includegraphics[width=\textwidth]{figure/samplepics-4}
\end{subfigure}
\begin{subfigure}[t]{0.28\textwidth}
  \caption{Color + Ellipse}
  \includegraphics[width=\textwidth]{figure/samplepics-5}
\end{subfigure}
\begin{subfigure}[t]{0.28\textwidth}
  \caption{Shape + Ellipse}
  \includegraphics[width=\textwidth]{figure/samplepics-6}
\end{subfigure}
\begin{subfigure}[t]{0.28\textwidth}
  \caption{Trend}
  \includegraphics[width=\textwidth]{figure/samplepics-7}
\end{subfigure}
\begin{subfigure}[t]{0.28\textwidth}
  \caption{Trend + Error }
  \includegraphics[width=\textwidth]{figure/samplepics-8}
\end{subfigure}
\begin{subfigure}[t]{0.28\textwidth}
  \caption{Trend + Color}
  \includegraphics[width=\textwidth]{figure/samplepics-9}
\end{subfigure}
\begin{subfigure}[t]{0.28\textwidth}
  \caption{Trend + Color + Ellipse}
  \includegraphics[width=\textwidth]{figure/samplepics-10}
\end{subfigure}
\caption{Each of the 10 plot feature combinations tested in this study, with $K=3$, $\sigma_T=0.25$ and $\sigma_C=0.20$. \label{fig:plotExamples}}
\end{figure}


\begin{table}[h]
\centering
\begin{tabular}{ccccc}
\begin{tabular}{c} \phantom{.}\\ \phantom{.} \end{tabular} && \multicolumn{3}{c}{\cellcolor{gray!25} Line Emphasis} \\
& Strength & 0 & 1 & 2 \\
\cellcolor{gray!25}\begin{tabular}{c} \phantom{.}\\ \phantom{.} \end{tabular} & 0 &  \cellcolor{gray!5} None &  \cellcolor{gray!15} Line &  \cellcolor{gray!25} Line + Prediction \\
\cellcolor{gray!25}\begin{tabular}{c} \\ Cluster \end{tabular} & 1 &  \cellcolor{gray!15}\begin{tabular}{c}Color\\ Shape\end{tabular} & \cellcolor{gray!5} Color + Line \\
\cellcolor{gray!25}\begin{tabular}{c}  Emphasis\\ \phantom{.} \end{tabular} & 2 & \cellcolor{gray!25}\begin{tabular}{c} Color + Shape\\ Color + Ellipse \end{tabular} && \cellcolor{gray!5}\begin{tabular}{c} Color + Ellipse +\\
Line + Prediction \end{tabular}\\
\cellcolor{gray!25}\begin{tabular}{c} \phantom{.}\\ \phantom{.} \end{tabular} & 3 & \cellcolor{gray!35} Color + Shape + Ellipse 
\end{tabular}
\caption{Plot aesthetics and statistical layers which impact perception of statistical plots, according to gestalt theory. \label{tab:plotaesthetics}}
\end{table}

\afterpage{\clearpage}

We expect that relative to a plot with no extra aesthetics or statistical layers, the addition of color, shape, and 95\% boundary ellipses  increases the probability of a participant selecting the target plot with data generated from $M_C$, the cluster model, and that the addition of these aesthetics  decreases the probability of a participant selecting the target plot with data generated from $M_T$, the linear model. 

Similarly, we expect that relative to a plot with no extra aesthetics or statistical layers, the addition of a trend line and prediction interval  increases the probability of a participant selecting the target plot with data generated from $M_T$, the linear model, and decreases the probability of a participant selecting the target plot with data generated from $M_C$, the cluster model.

\subsubsection{Experimental Design}
The study is designed hierarchically, as a factorial experiment for combinations of $\sigma_C$, $\sigma_T$, and $K$, with three replicates at each parameter combination. These parameters are used to generate lineup datasets which serve as blocks for the plot aesthetic level of the experiment; each dataset is rendered with every combination of aesthetics described in table \ref{tab:plotaesthetics}. Participants are assigned to generated plots according to an augmented balanced incomplete block scheme: each participant is asked to evaluate 10 plots, which consist of one plot at each combination of $\sigma_C$ and $\sigma_T$, randomized across levels of $K$, with one additional plot providing replication of one level of $\sigma_C\times\sigma_T$. Each of a participant's 10 plots will present a different aesthetic combination.

%\newdo{Need to find some graphic/table which makes this a bit more clear.}

\subsubsection{Color and Shape Palettes}
Colors and shapes used in this study were selected in order to maximize preattentive feature differentiation. \citet{heer:2014} provide sets of 10 colors and 10 shapes, with corresponding distance matrices, determined by user studies. Using these perceptual kernels for shape and color, we identified sets of 3 and 5 colors and shapes which maximize the sum of pairwise differences, subject to certain constraints imposed by software and accessibility concerns. 

\begin{figure}
<<color-palette, dev='cairo_pdf', echo=FALSE, fig.width=5, fig.height=1, out.width='.5\\linewidth',dependson='setup'>>=
colors <- c("#1f77b4", "#ff7f0e", "#2ca02c", "#d62728", "#9467bd", 
            "#8c564b", "#e377c2", "#7f7f7f", "#bcbd22", "#17becf")
qplot(x=1:10, y=0, color=colors, size=I(5)) + scale_color_identity() + theme_lineup()
@
\caption{Colors in \citet{heer:2014}. This study removed gray from the palette to make the experiment more inclusive of participants with colorblindness.\label{fig:colors}}
\end{figure}

The color palette used in \citet{heer:2014} and shown in figure \ref{fig:colors} is derived from colors available in Tableau visualization software. \comment{citation for Tableau?}
In order to produce experimental stimuli accessible to the approximately 4\% of the population with red-green color deficiency \citep{colorvision}, we removed the gray hue from the palette. This modification produced maximally different color combinations which did not include red-green combinations, while also removing a color (gray) which is difficult to distinguish for those with color deficiency.  

% Beyond that, we modified some color pairings observed in the general population to reflect individual's abilities: the red-green color pair is one of the pairs of the most distinct color pairings in the general population (XXX exact value?), but obviously is a poor choice for the approximately XXX\% of population with a red-green color vision deficiency.

\begin{figure}
<<shape-palette, dev='cairo_pdf', echo=FALSE, fig.width=5, fig.height=1, out.width='.5\\linewidth',message=F, warning=F>>=
shapes <- c(1,0,3,4,8,5,2,6,-0x25C1, -0x25B7)

qplot(x=1:10, y=0, shape=shapes, size=I(5)) + scale_shape_identity() + theme_lineup()
@
\caption{Shapes in \citet{heer:2014}. In order to control for varying point size due to Unicode vs. non-Unicode characters, the last two shapes were removed.\label{fig:shapes}}
\end{figure}

Software compatibility issues led us to exclude two shapes used in \citet{heer:2014} and shown in figure \ref{fig:shapes}. The left and right triangle shapes (available only in unicode within R) were excluded due to size differences between unicode and non-unicode shapes. After optimization over the sum of all pairwise distances, the maximally different shape sequences for the 3 and 5 group datasets also conform to the guidelines in \citet{robinson:03}: for $K=3$ the shapes are from Robinson's group 1, 2, and 9, for $K=5$ the shapes are from groups 1, 2, 3, 9, and 10. Robinson's groups are designed so that shapes in different groups show differences in preattentive properties; that is, they are easily distinguishable. In addition, all shapes are non-filled shapes, which means that they are consistent with one of the simplest solutions to overplotting of points in the tradition of \citet{tukey, cleveland:85} and \citet{few}. For this reason we abstained from the additional use of alpha-blending of points to diminish the effect of overplotting in the plots.

\subsection{Hypotheses}
The primary purpose of this study is to understand how visual aesthetics affect signal detection in the presence of competing signals. We expect that plot modifications which emphasize similarity and proximity, such as color, shape, and 95\% bounding ellipses, will increase the probability of detecting the clustering relationship, while plot modifications which emphasize good continuation, such as trend lines and prediction intervals, will increase the probability of detecting the linear relationship. 


A secondary purpose of the study is to relate signal strength (as determined by dataset parameters $\sigma_C$, $\sigma_T$, and $K$) to signal detection in a visualization by a human observer.


\subsection{Participant Recruitment}
% \newdo{describe amazon turk, participant instructions, screening procedures, etc.}
Participants were recruited using Amazon's Mechanical Turk service, which connects interested workers with ``Human Intelligence Tasks" (HITs), which are (typically) short tasks which cannot be easily automated. Only workers with at least 100 previous HITs at a 95\% successful completion rate were allowed to sign up for completing the task. These restrictions reduce the amount of data cleaning required by ensuring that participants have experience with the Mechanical Turk system. 

Participants were asked to complete an example task similar to the task in the experiment before deciding whether or not to complete the HIT. The lineups used as examples contained only one target (5 trend and 5 cluster trials were provided), and participants had to correctly identify target plots in at least two lineups before being allowed into  the HIT and proceeding to the experimental phase. The webpage used to collect data from Amazon Turk participants is available at \url{http://www.mlcape.com:8080/mahbub/turk16/index.html}. No data was recorded from the example task because participants had not yet provided informed consent. 

Once participants completed the example task and provided informed consent, they could accept the HIT through Amazon and were directed to the main experimental task. 
Participants were required to complete 10 lineups, answering ``Which plot is the most different from the others?". Participants were asked to provide a short reason for their choice, such as ``Strong linear trend" or ``Groups of points", and to rate their confidence in their selection from 1 (least confident) to 5 (most confident). 
After the first question, basic demographic information was collected: age range, gender, and highest level of education. 

%Upon completion of 10 lineups, participants were provided with a text code to enter into Amazon Turk in order to receive the advertised payment of \$1.00. Participants took (on average) 8 minutes to complete the HIT (not including the required example task).



\section{Results}\label{sec:Results}
<<results-setup,echo=F,include=F>>=
lineups <- read.csv("../../Images/Turk16/data-picture-details-gini.csv", stringsAsFactors=FALSE)
lineups$pic_id_old <- lineups$pic_id
lineups$pic_id <- 1:nrow(lineups)

users <- read.csv("../../Images/Turk16/turk16_users.csv", stringsAsFactors=F, header=F)
names(users) <- c("nick_name", "age", "gender", "education", "ip_address")
users$age <- factor(users$age, levels=0:10, labels=c("NA", "<18", "18-25", "26-30", "31-35", "36-40", "41-45", "45-50", "51-55", "56-60", "61+"))
users$gender <- factor(users$gender, levels=0:2, labels=c("NA", "Male", "Female"))
users$education <- factor(users$education, levels=0:5, labels=c("NA", "High School or less", "Some college", "Bachelor's degree", "Some graduate school", "Graduate degree"))

userdata <- read.csv("../../Data/turk16_results.csv", stringsAsFactors=FALSE)
userdata$response.id <- 1:nrow(userdata)
# table(userdata$ip_address, userdata$nick_name)

tmp <- merge(userdata[!is.na(userdata$pic_id),], lineups[,c("pic_id", "sample_size", "test_param", "param_value", "p_value", "obs_plot_location")], all.x=T, all.y=F)
tmp$k <- as.numeric(substr(tmp$param_value, 3, 3))
tmp$sd.line <- as.numeric(substr(tmp$param_value, 12, 15))
tmp$sd.cluster <- as.numeric(substr(tmp$param_value, 25, 28))

correct.ans <- function(x,y){
  x1 <- as.numeric(str_trim(unlist(str_split(x, ","))))
  answers <- str_trim(unlist(str_split(y, ",")))
  lineplot <- as.numeric(answers[1])
  groupplot <- as.numeric(answers[2])
  giniplot <- ifelse(groupplot==as.numeric(answers[3]) | lineplot==as.numeric(answers[3]), NA, as.numeric(answers[3]))
  c(n.answers=length(x1), trend.correct=lineplot%in%x1, cluster.correct=groupplot%in%x1, both.correct = lineplot%in%x1 & groupplot%in%x1, neither.correct=!(lineplot%in%x1 | groupplot%in%x1), none.correct=!(lineplot%in%x1 | groupplot%in%x1 | giniplot%in%x1), gini.correct=giniplot%in%x1)
}

useranswers <- ddply(tmp, .(response.id), function(df) correct.ans(df$response_no, df$obs_plot_location))
useranswers <- merge(useranswers, tmp)
useranswers$plottype <- gsub("turk16-", "", useranswers$test_param)
useranswers$plottype <- factor(useranswers$plottype, levels=c("plain", "trend", "color", "shape", "colorShape", "colorEllipse", "colorTrend",  "trendError", "colorShapeEllipse", "colorEllipseTrendError"))
useranswers$sd.cluster <- factor(useranswers$sd.cluster)
useranswers$sd.line <- factor(useranswers$sd.line)
useranswers$k <- factor(useranswers$k)
useranswers$start_time <- ymd_hms(useranswers$start_time)
useranswers$end_time <- ymd_hms(useranswers$end_time)
useranswers <- ddply(useranswers, .(param_value, test_param), transform, param_idx=as.numeric(factor(pic_id)))
useranswers <- ddply(useranswers, .(ip_address, nick_name), transform, ntrials = length(unique(pic_id)), trial.no = rank(start_time), trial.num=order(start_time))

# Remove data from <18 participants
useranswers <- filter(useranswers, !nick_name%in%users$nick_name[users$age=="<18"])
users <- filter(users, age!="<18")

modeldata <- useranswers[,c(1, 2, 9:30, 3:8)]

# Remove data from participants who did not complete 10 trials
incomplete.participants <- unique(modeldata$nick_name[modeldata$ntrials<10])
incomplete.participant.data <- sum(modeldata$ntrials<10)
message(paste0(sum(modeldata$ntrials<10), " trials removed because participant completed <10 trials total."))
# Remove data from participants who completed > 10 trials
modeldata <- filter(modeldata, ntrials>=10)
extra.participant.data <- sum(modeldata$trial.num>10)
message(paste0(sum(modeldata$trial.num>10), " trials removed because participant >10 trials."))
modeldata <- filter(modeldata, trial.num<=10)
# Remove users from database who didn't complete any trials
message(paste0(sum(!users$nick_name%in%modeldata$nick_name), " users removed from user database - no trials found."))
users <- users %>% filter(nick_name%in%modeldata$nick_name)
modeldata <- modeldata[,-30]

modeldata$outcome <- paste(c("", "trend")[1+as.numeric(modeldata$trend.correct==1)], 
                           c("", "cluster")[1+as.numeric(modeldata$cluster.correct==1)], 
                           c("", "neither")[1+as.numeric(modeldata$neither.correct==1)], 
                           c("", "gini")[1+as.numeric(modeldata$gini.correct==1)], 
                           sep="")
modeldata$outcome[modeldata$both.correct==1] <- "both"
modeldata$first.trial <- modeldata$trial.no == 1
modeldata$simpleoutcome <- gsub("gini", "", modeldata$outcome)
modeldata$simpleoutcome <- factor(modeldata$simpleoutcome, levels=c("neither", "cluster", "trend","both"))

modeldata <- merge(modeldata, lineups[,c("pic_id", "data_name", "param_value")], all.x=T, all.y=T)
modeldata$dataset <- factor(str_extract(modeldata$data_name, "set-\\d{1,3}") %>% str_replace("set-", "") %>% as.numeric)
modeldata$individualID <- factor(sprintf("%s-%s", modeldata$ip_address, modeldata$nick_name))
modeldata$k <- factor(modeldata$k, levels=c(3, 5))
modeldata$parameter.value <- factor(gsub("set-\\d{1,3}-", "", modeldata$data_name))
modeldata$start_time <- ymd_hms(modeldata$start_time)
modeldata$end_time <- ymd_hms(modeldata$end_time)
modeldata$trial.time <- with(modeldata, end_time-start_time)
modeldata <- ddply(modeldata, .(k), transform, trend.diff=c("easy", "medium", "hard")[as.numeric(droplevels(sd.line))], cluster.diff=c("easy", "medium", "hard")[as.numeric(droplevels(sd.cluster))])
modeldata$trend.diff <- factor(modeldata$trend.diff, levels=c("easy", "medium", "hard"))
modeldata$cluster.diff <- factor(modeldata$cluster.diff, levels=c("easy", "medium", "hard"))
modeldata$cluster.diff2 <- factor(modeldata$cluster.diff, levels=c("easy", "medium", "hard"), labels=c("Cluster: Easy", "Cluster: Medium", "Cluster: Hard"))
modeldata$trend.diff2 <- factor(modeldata$trend.diff, levels=c("easy", "medium", "hard"), labels=c("Trend: Easy", "Trend: Medium", "Trend: Hard"))

parameter.design <- unique(modeldata[,c("dataset", "k", "trend.diff", "cluster.diff")])

plot.eval.tab <- apply(with(modeldata, table(dataset, plottype)), 1:2, sum)

# long dataset for table-esque plots
modeldata.long <- melt(modeldata, id.vars=which(!grepl("(correct)|(outcome)", names(modeldata))), value.vars=c("trend.correct", "cluster.correct", "neither.correct"), value.name="correct", variable.name="answer.type")
modeldata.long$answer.type <- gsub(".correct", "", modeldata.long$answer.type)
modeldata.long <- filter(modeldata.long, answer.type%in%c("cluster", "trend", "neither"))
modeldata.long$correct <- as.numeric(modeldata.long$correct)
modeldata.long$answer.type <- factor(modeldata.long$answer.type, levels=c("cluster", "trend", "neither"))
modeldata.long$plottype <- 
  modeldata.long$plottype %>%
  str_replace("color", "Color + ") %>% 
  str_replace("[sS]hape", "Shape + ") %>%
  str_replace("[tT]rend", "Trend + ") %>%
  str_replace("Ellipse", "Ellipse + ") %>%
  str_replace("Error", "Error + ") %>%
  str_replace("plain", "Plain") %>%
  str_replace("( \\+ )$", "") %>% 
  factor(levels=c("Plain", "Color", "Shape", "Trend", "Trend + Error", 
                  "Color + Shape", "Color + Ellipse", "Color + Trend", 
                  "Color + Shape + Ellipse", "Color + Ellipse + Trend + Error"),
         labels=c("Plain", "Color", "Shape", "Trend", "Trend + Error", 
                  "Color + Shape", "Color + Ellipse", "Color + Trend", 
                  "Color + Shape + Ellipse", "Color + Ellipse + Trend + Error"))


totaltime <- ddply(modeldata, .(individualID), summarize, total.experiment.time = max(end_time)-min(start_time))
@

\subsection{General results}

Data collection was conducted over a \Sexpr{round(as.numeric(difftime(max(modeldata$end_time), min(modeldata$start_time), units="hours")))} hour period, % how cool is that... 25 hours and voila: data!
during which time \Sexpr{length(unique(userdata$nick_name))} individuals completed \Sexpr{nrow(userdata)} unique lineup evaluations. Participants who completed fewer than 10 lineups were removed from the study (\Sexpr{length(incomplete.participants)} participants, \Sexpr{incomplete.participant.data} evaluations), and lineup evaluations in excess of 10 for each participant were also removed from the study (\Sexpr{extra.participant.data} evaluations). 
After these data filtration steps, our data consist of \Sexpr{nrow(modeldata)} trials completed by \Sexpr{length(unique(modeldata$individualID))} participants. 

Of the participants who completed at least 10 lineup evaluations, \Sexpr{round(mean(users$gender=="Male")*100)}\% were male, relatively younger than the US population and relatively well educated (see figure~\ref{fig:demographics}).

\begin{figure}[ht]
<<demographics, echo=FALSE, fig.width=7.5, fig.height=5, fig.keep='all', fig.show='hold', out.width='.48\\textwidth'>>=
# cage <- read.csv("../../data/census-age.csv")
# cage$order <- 1:nrow(cage)
# cage$Census.age <- reorder(cage$Census.age, cage$order)
# cage2 <- cage[-(1:3),]
# levels(cage2$Census.age) <- gsub("   .","", levels(cage2$Census.age))
# cage2$perc <- cage2$Number/sum(cage2$Number) * nrow(users)
# qplot(Census.age, weight=perc, data=cage2)
qplot(age, data=users) + theme_bw() + xlab("Age of participants") + ylab("# Participants") + ggtitle("Participant Age Distribution")

qplot(education, data=users) + theme_bw() + xlab("(self-reported) Highest level of participants' education") + ylab("# Participants") + ggtitle("Participant Education Levels")
@
\caption{\label{fig:demographics}Basic demographics of participants.}
\end{figure}
%and 
%\Sexpr{round(mean(users$age%in%c("18-25", "26-30"))*100)}
%\% were between 18 and 30 years of age. 


%\newtext{
%Participants were fairly well-educated: 
%\Sexpr{round(mean(users$education%in%levels(users$education)[3:4])*100)}\% had at least some undergraduate education, and 
%\Sexpr{round(mean(users$education%in%levels(users$education)[5:6])*100)}\% had at least some graduate education. 



Each plot was evaluated by between \Sexpr{min(plot.eval.tab)} and \Sexpr{max(plot.eval.tab)} individuals 
(\Sexpr{sprintf("Mean: %.2f, SD= %.2f", mean(plot.eval.tab), sd(plot.eval.tab))}).

\Sexpr{round(100*(1-mean(modeldata$neither.correct)), 1)}\% of the participant evaluations identified at least one of the two target plots successfully (Trend: \Sexpr{round(100*(mean(modeldata$trend.correct)), 1)}\%, Cluster: \Sexpr{round(100*(mean(modeldata$cluster.correct)), 1)}\%). 

Only \Sexpr{round(100*(mean(modeldata$n.answers>=2)), 1)}\% of participant evaluations identified more than one target plot, and of these multiple identifications, \Sexpr{round(100*(mean(modeldata[modeldata$n.answers>=2,"both.correct"])), 1)}\% identified both targets correctly. 

From figure~\ref{fig:targets} we see that users identified more cluster targets than trend targets, but users also do not primarily identify one target type over another target type, but generally pick both types over the course of ten lineups.
\begin{figure}
\centering
<<targets, fig.width=7.5, fig.height=5, out.width='0.6\\textwidth', echo=FALSE>>=
user.data <- modeldata %>% group_by(individualID) %>% 
  summarize(answers=length(individualID),
            cluster=sum(cluster.correct),
            trend=sum(trend.correct))
clusters <- as.data.frame(table(user.data$cluster))
trends <- as.data.frame(table(user.data$trend))
names(clusters) <- c("x", "Cluster")
clusters$Trend <- trends$Freq 
clm <- melt(clusters, measure.var=2:3)

ggplot() + geom_point(aes(x, value, colour=variable, shape=variable), size=3, data=clm) + theme_bw() + scale_colour_brewer("Target", palette="Set1") + scale_shape_discrete("Target") + theme(legend.position="bottom") + ylab("Number of participants") + xlab("Number of target identifications (out of ten)") + geom_line(aes(x, value, colour=variable, group=variable), data=clm) 
@
\caption{\label{fig:targets}Target identifications by users. Users are not generally primed for one target over the other target.}
\end{figure}

We  first consider the effect of plot aesthetics on target selection for each target type (separately), and then compare the probability of selecting the cluster target compared with the trend target as a function of plot aesthetics. Finally, we will consider data on response times for each type of plot.

\subsection{Single Target Plot Models}

We  model the probability of selecting the linear target plot as a logistic regression with plot type as a fixed effect, and random effects for dataset (which encompasses parameter effects) and participant (accounting for variation in individual skill level). 

For plot type $i$, displaying dataset $j=1, ..., 54$ and participant $k=1, ..., P$, we model
%
\begin{align}
\text{logit }P(\text{success}) & =  \textbf{X}\beta + \textbf{J}\gamma + \textbf{K}\eta + \epsilon, \label{eqn:linearModel}\\
\text{where } \beta_i & \hphantom{\sim} \text{describe the effect of specific plot aesthetics}\nonumber\\
\hphantom{where } \gamma_j & \overset{iid}{\sim} N\left(0, \sigma^2_{\text{data}}\right)\text{, the random effect for dataset specific characteristics}\nonumber\\
\hphantom{where } \eta_k & \overset{iid}{\sim} N\left(0, \sigma^2_{\text{participant}}\right)\text{, the random effect for participant characteristics}\nonumber\\
\text{and } \epsilon_{ijk} & \overset{iid}{\sim}  N\left(0, \sigma^2_e\right)\text{, the error associated with a single trial evaluation} \nonumber
\end{align}

We note that any variance due to parameters $K$, $\sigma_T$, and $\sigma_C$ is contained within $\sigma^2_{\text{data}}$ and can be examined using a subsequent model. 

\subsubsection{Linear Target Model}

<<line-model, echo=FALSE, include=FALSE, dependson='results-setup'>>=
line.model <- glmer(trend.correct ~ plottype + (1|individualID) + (1|dataset), 
                    data = modeldata, 
                    family = binomial(link="logit"), 
                    control=glmerControl(optimizer="bobyqa"))
line.fixef <- data.frame(summary(line.model)$coefficients, confint(line.model, method="Wald"))
names(line.fixef) <- c("Estimate", "StdError", "Z", "p value", "LB", "UB")
line.fixef$OR <- exp(line.fixef[,1])
line.fixef$label <- gsub("(Intercept)", "", gsub("plottype", "", rownames(line.fixef)), fixed=T)

suppressMessages(require(multcomp))
type_compare <- glht(line.model, mcp(plottype="Tukey"))
line.fixef$letters <- cld(type_compare)$mcletters$Letters
@

<<line-fixef, echo=FALSE, include=FALSE, dependson='line-model', fig.width=8, fig.height=4>>=
line.fixef.aes <- line.fixef[grepl("(color)|([Ss]hape)|([Tt]rend)|(Ellipse)|(Error)", rownames(line.fixef)),]
line.fixef.aes <- line.fixef.aes[order(line.fixef.aes$OR, decreasing = T),]
line.fixef.aes$label <- 
  line.fixef.aes$label %>% 
  str_replace("color", "Color + ") %>% 
  str_replace("[sS]hape", "Shape + ") %>%
  str_replace("[tT]rend", "Trend + ") %>%
  str_replace("Ellipse", "Ellipse + ") %>%
  str_replace("Error", "Error + ") %>%
  str_replace("( \\+ )$", "")
line.fixef.aes$label <- factor(line.fixef.aes$label, levels=line.fixef.aes$label[order(line.fixef.aes$OR, decreasing = T)], ordered=T)
line.fixef.aes$LB <- exp(line.fixef.aes$LB)
line.fixef.aes$UB <- exp(line.fixef.aes$UB)

qplot(data=line.fixef.aes, x=label, y=OR, ymin=LB, ymax=UB, geom="pointrange") + 
  geom_text(aes(x=label, y=0, label=letters)) + 
  coord_flip() + 
  ylab("Odds + 95% Wald Interval") + 
  xlab("Plot Type") + 
  geom_hline(yintercept=1, colour="gray70") +
  ggtitle("Odds of Selecting Line Target Plot") + 
  theme_bw()

names(line.fixef.aes)[1:4] <- c("Log Odds", "Std. Error", "Z", "P value")
names(line.fixef.aes)[8] <- "Plot Aesthetic"
names(line.fixef.aes)[9] <- "Tukey Post Hoc Differences"
#print(xtable(line.fixef.aes[,c(8, 1:4, 9)], caption=c("Fitted values of fixed effects for the model described in \\eqref{eqn:linearModel}. Only Trend+Error plots significantly increase the probability of detecting the linear target plot (with data generated from $M_T$), while most other aesthetic combinations decrease the probability of detecting the linear target plot.", "Fixed effects for linear target logistic model"), label="tab:line.fixef", align=c('r', 'r', 'r', 'r', 'r', 'r', 'r'), digits=c(0, 0, 4, 4, 2, 4, 0)), include.rownames=F, file="figure/linear-fixef-table")
print(xtable(line.fixef.aes[,c(8, 1:4)], caption=c("Fitted values of fixed effects for the model described in \\eqref{eqn:linearModel}. Only Trend+Error plots significantly increase the probability of detecting the linear target plot (with data generated from $M_T$), while most other aesthetic combinations decrease the probability of detecting the linear target plot.", "Fixed effects for linear target logistic model"), label="tab:line.fixef", align=c('r', 'r', 'r', 'r', 'r', 'r'), digits=c(0, 0, 4, 4, 2, 4)), include.rownames=F, file="figure/linear-fixef-table")
@

\begin{figure}\centering
\includegraphics[width=.75\linewidth]{figure/line-fixef-1}
\caption{Odds of detecting the linear target plot for each aesthetic. Only the combination of Trend + Error significantly increases the odds of linear target plot detection relative to the control plot (plain scatterplot). \label{fig:linear.fixef}}
\end{figure}

%\comment{Be careful with using `odds' versus `odds ratio'. they are not the same. In the model we discuss odds not odds ratios.}

Figure \ref{fig:linear.fixef} shows the fixed effects of the linear target model fitted according to equation \ref{eqn:linearModel}. Aesthetic combinations which would be expected to emphasize similarity under gestalt principles significantly decrease the probability of selecting the target plot generated under $M_T$, the trend data model. Only the dual continuity emphasis of Trend + Error bars significantly increases the probability that participants will identify the target plot generated under $M_T$. 


\subsubsection{Group Target Selection}\label{sec:groupModel}

We now examine the probability of selecting the group target plot as a function of plot type, with random effects for dataset (which encompasses parameter effects) and participant (accounting for variation in individual skill level). The model fit here is the same as that shown in equation \eqref{eqn:linearModel}, except that success in this model is defined as identification of the cluster target plot. 


<<group-model, echo=FALSE, include=FALSE, dependson='results-setup'>>=
group.model <- glmer(cluster.correct~ plottype + (1|individualID) + (1|dataset), 
                     data = modeldata, 
                     family = binomial(link="logit"), 
                     control=glmerControl(optimizer="bobyqa"))
group.fixef <- data.frame(summary(group.model)$coefficients, confint(group.model, method="Wald"))
names(group.fixef) <- c("Estimate", "StdError", "Z", "p value", "LB", "UB")
group.fixef$OR <- exp(group.fixef[,1])
group.fixef$label <- gsub("(Intercept)", "", gsub("plottype", "", rownames(group.fixef)), fixed=T)

suppressMessages(require(multcomp))
type_compare <- glht(group.model, mcp(plottype="Tukey"))
group.fixef$letters <- cld(type_compare)$mcletters$Letters

@

<<group-fixef, echo=FALSE, include=FALSE, dependson='group-model', fig.width=8, fig.height=4>>=
group.fixef2 <- group.fixef[2:10,]
group.fixef2 <- group.fixef2[order(group.fixef2$OR, decreasing = T),]
group.fixef2$label <- 
  group.fixef2$label %>% 
  str_replace("color", "Color + ") %>% 
  str_replace("[sS]hape", "Shape + ") %>%
  str_replace("[tT]rend", "Trend + ") %>%
  str_replace("Ellipse", "Ellipse + ") %>%
  str_replace("Error", "Error + ") %>%
  str_replace("( \\+ )$", "")
group.fixef2$label <- factor(group.fixef2$label, levels=group.fixef2$label[order(group.fixef2$OR, decreasing = T)], ordered=T)
group.fixef2$LB <- exp(group.fixef2$LB)
group.fixef2$UB <- exp(group.fixef2$UB)

qplot(data=group.fixef2, x=label, y=OR, ymin=LB, ymax=UB, geom="pointrange") + 
  geom_text(aes(x=label, y=0.3, label=letters)) + 
  coord_flip() + 
  scale_y_continuous("Odds + 95% Wald Interval", breaks=c(.5, .75, 1, 1.25)) + 
  xlab("Plot Type") + 
  geom_hline(yintercept=1, colour="gray70") +
  ggtitle("Odds of Selecting Group Target Plot") + 
  theme_bw()

names(group.fixef2)[1:4] <- c("Log Odds", "Std. Error", "Z", "P value")
names(group.fixef2)[8] <- "Plot Aesthetic"
names(group.fixef2)[9] <- "Tukey Post Hoc Differences"
#print(xtable(group.fixef2[,c(8, 1:4, 9)], caption=c("Fitted values of fixed effects for the model described in section~\ref{sec:groupModel}.", "Fixed effects for group target logistic model"), label="tab:group.fixef", align=c('r', 'r', 'r', 'r', 'r', 'r', 'r'), digits=c(0, 0, 4, 4, 2, 4, 0)), include.rownames=F, file="figure/group-fixef-table")
print(xtable(group.fixef2[,c(8, 1:4)], caption=c("Fitted values of fixed effects for the model described in section~\ref{sec:groupModel}.", "Fixed effects for group target logistic model"), label="tab:group.fixef", align=c('r', 'r', 'r', 'r', 'r', 'r'), digits=c(0, 0, 4, 4, 2, 4)), include.rownames=F, file="figure/group-fixef-table")

@

\begin{figure}\centering
\includegraphics[width=.75\linewidth]{figure/group-fixef-1}
\caption{Odds of detecting the cluster target plot for each aesthetic, relative to a plain scatterplot. The presence of error lines or bounding ellipses significantly decreases the probability of correct target detection, and no aesthetic successfully increases the probability of correct target detection. This may be due to differences in group size for null plots, with data generated under $M_0$ compared with the group target plot displaying data generated under $M_C$. \label{fig:group.fixef}}
\end{figure}


Figure \ref{fig:group.fixef} contains odds and intervals of the estimated fixed effects obtained by fitting equation \ref{eqn:linearModel} to a binary indicator of successful cluster target identification. 
According to the model results, no plot aesthetics significantly increase the likelihood of selecting the group target plot; however, several aesthetic combinations decrease this likelihood. Consistent with our hypothesis,  Color + Ellipse + Trend + Error and Trend + Error plot aesthetic combinations significantly decrease the detection of the group target plot. 

However, Color + Ellipse and Color + Shape + Ellipse also decrease group target detection is not consistent with our hypotheses. Examination of participants' reasons for selecting specific target plots provides at least some explanation; participants cited reasons such as 
``There is no circle highlighting the yellow symbols in this plot" %line 13515 
and 
``Lack of a circle around the red symbols".  %line 13516

This suggests that our group allocation for null target plots may have produced unintentional results; rather than providing unambiguous gestalt cues which reinforced group separation, instead, our null plots provided mixed cues which varied the number of groups and the presence of the additional similarity cue. 
Numerically, these null data sets had uneven group allocation; bounding ellipse estimation failed for groups with fewer than 3 points and in these cases, ellipses were not drawn. 
Visually, the conspicuous absence of an ellipse will lead participants to select null plots with that feature \newtext{(see section~\ref{sec:sentiment} for a more detailed look at participants' responses)}.
This effect actually provides some additional information as to the hierarchy of gestalt features: for plots displaying the same data (including at least one plot with group size $<3$), participants were more likely to identify the group target plot under the Color and Shape aesthetics than under Color + Ellipse or Color + Shape + Ellipse conditions. 
The presence of the ellipse (and the gestalt common region heuristic) dominated the effect of point similarity (albeit not in the way the authors originally intended). 
In future experiments, it will be advantageous to control the variability in group size in order to remove the conflicting visual influence of gestalt common region heuristics with the greater similarity and proximity present in the target plot. 




\subsection{Face-Off: Trend versus Cluster}
Next, we consider only the subset of trials in which participants identified one of the two target plots. For these trials, we compare the probability of selecting the cluster target generated by $M_C$ compared with the probability of selecting the trend target generated by $M_T$. Overall, participants favored clusters to trends at a ratio of about 2:1. We remove this effect using an intercept, and model group vs. line decisions using a logistic regression with a random effect for each dataset to account for different difficulty levels in the generated data. The estimated odds of a decision in favor of group over line target are shown in figure~\ref{fig:faceoff}. From left to right the odds of selecting the group target  over the line target increase. As hypothesized, the strongest signal for identifying groups, is color + shape + ellipse, while trend + error results in the strongest signal in favor of trends. Most of the effects are not significantly different (see the letter values \cite{piepho:04} based on Tukey's Post Hoc difference tests   on the left hand side of the figure, representing pairwise comparisons of all of the designs, adjusted for multiple comparison). Trend+error plots and ellipse+trend plots are significantly different from all of the other designs. Apart from that, the only significant difference between designs is between color+shape+ellipse plots and trend plots.

\begin{figure}
\centering
<<group-vs-line, echo=FALSE, fig.width=8, fig.height=4, out.width='.85\\textwidth'>>=
designs <- ddply(modeldata, .(dataset, plottype), summarise, evals=length(data_name), group=sum(cluster.correct), line=sum(trend.correct))
designs$perc <- with(designs, group/(group+line))
#qplot(plottype, perc, data=designs, geom="boxplot")
gvl.model <- glmer(cbind(group, line)~plottype+(1|dataset), data=designs, family=binomial())
gvl.fixef <- data.frame(confint(gvl.model, method="Wald"))
names(gvl.fixef) <- c("LB", "UB")
gvl.fixef$OR <- fixef(gvl.model)

suppressMessages(require(multcomp))
type_compare <- glht(gvl.model, mcp(plottype="Tukey"))
gvl.fixef$letters <- cld(type_compare)$mcletters$Letters

gvl.fixef$label <- gsub("plottype", "", names(fixef(gvl.model)))
gvl.fixef$label <- gvl.fixef$label %>% 
  str_replace("color", "Color + ") %>% 
  str_replace("[sS]hape", "Shape + ") %>%
  str_replace("[tT]rend", "Trend + ") %>%
  str_replace("Ellipse", "Ellipse + ") %>%
  str_replace("Error", "Error + ") %>%
  str_replace("( \\+ )$", "") %>% 
  reorder(gvl.fixef$OR)

ggplot(data=gvl.fixef[-1,]) + 
  geom_pointrange(aes(x=label, y=exp(OR), ymin=exp(LB), ymax=exp(UB))) + 
  coord_flip() + 
  theme_bw() + 
  geom_hline(yintercept=1, colour="gray70") + 
  ggtitle("Odds of Selecting Group vs Line Target \n (given one target was identified)") + 
  ylab("Odds (Group vs Line) and 95% Wald Intervals") + 
  xlab("Plot Type") + 
  geom_text(aes(y=0.4, x=label, label=letters))
@
\caption{\label{fig:faceoff} Estimated odds of decision for group versus line target based on evaluations that resulted in the identification of one of these targets. Plot types are significantly different, if they do not share a letter as given on the left hand side of the plot.}
\end{figure}


Examining the model results from the perspective of Gestalt heuristics, it is clear that the similarity/proximity effect, as indicated by spatial clustering and aesthetics such as color and shape, dominates the equation, including dominating the color+trend (good continuation) condition.  

When trend and error are present in the same plot, additional Gestalt ordering principles are present: common region and closure (due to the enclosed space between the two error lines), in addition to the good continuation heuristic present due to the trend line and the linear relationship between $x$ and $y$. The interaction between these three heuristics dominates the perceptual experience, decreasing the probability that a participant will select the cluster target plot (and increasing the probability that the trend target will be selected). 

This interaction effect explains the different outcomes seen by the two conditions with conflicting aesthetics: the color+trend condition is more likely to result in cluster plot selection, while the color + ellipse + trend + error condition is more likely to result in trend plot selection, because the combined effect of the gestalt heuristics present in the trend+error elements is stronger than the effect of color + ellipse elements, which only invoke Gestalt heuristics of similarity and common region. 


\subsection{Response Time}


As data collection was conducted entirely online, we cannot measure responses in the millisecond range characteristic of many psychometric studies, however, the data server does record the time between initial lineup presentation (trial start) and answer submission (trial end). 
% \comment{it is not clear, how the `trial' is defined. it might be better to re-phrase this in terms of the time between presenting the lineup to the participant until the participant submits his/her answer. }
Examining differences in average response times across trials provides us with an additional measure of trial difficulty or perceptual complexity. 
We can also explore whether participants spent more time on certain types of plots and how additional time is realted to accurate target identification. 

\begin{figure}
<<timemodel-plottype, echo=FALSE, fig.width=8, fig.height=6, out.width='\\textwidth', dependson='results-setup'>>=
library(lubridate)

# modeldata$time_taken <- as.numeric(ymd_hms(modeldata$end_time) - ymd_hms(modeldata$start_time))
time.model <- lmer(log(as.numeric(trial.time))~ simpleoutcome:plottype + first.trial  + (1|individualID) + (1|dataset), data=modeldata)

coefs <- data.frame(exp(confint(time.model, method="Wald")))[-c(1:2),]
names(coefs) <- c("low", "high")
coefs$estimate <- exp(fixef(time.model)[-c(1:2)])
coefs$name <- names(fixef(time.model))[-c(1:2)]
ll <- ldply(strsplit(coefs$name, split=":"), function(x) x)
coefs$outcome <- gsub("simpleoutcome", "", ll$V1)
coefs$plottype <- gsub("plottype", "", ll$V2)
coefs$simple <- coefs$outcome %in% c("both") - coefs$outcome%in%c("neither")
coefs$simple <- factor(coefs$simple)
levels(coefs$simple) <- c("Neither", "Cluster, Trend", "Both")
coefs$outcome <- factor(coefs$outcome, levels=c("neither", "cluster", "trend", "both"))

coefs$plottype <- coefs$plottype %>% 
  str_replace("color", "Color + ") %>% 
  str_replace("[sS]hape", "Shape + ") %>%
  str_replace("[tT]rend", "Trend + ") %>%
  str_replace("Ellipse", "Ellipse + ") %>%
  str_replace("Error", "Error + ") %>%
  str_replace("plain", "Plain") %>%
  str_replace("( \\+ )$", "")
coefs$plottype <- factor(coefs$plottype)

coefs$plottype <- with(coefs, reorder(plottype, estimate))

#coefs$pos <- as.numeric(factor(coefs$plottype)) +  (coefs$outcome!="neither")*(coefs$outcome!="both")*(as.numeric(factor(coefs$outcome))-3)/6
coefs$pos <- as.numeric(factor(coefs$plottype)) + as.numeric(coefs$outcome)/6 - 1/3

qplot(estimate, pos, data=coefs, colour=outcome, size=I(4), shape=outcome) + theme_bw() + 
  scale_colour_brewer("Target identified", palette="Set1") +
  scale_shape_discrete("Target identified") +
  geom_segment(aes(x=low, xend=high, y=pos, yend=pos)) + 
#  facet_wrap(~simple, scales="free_x") + 
  scale_y_continuous(breaks=1:10, labels=levels(coefs$plottype)) + 
  xlab("Additional time to evaluate each plot type (in seconds) given outcome") + ylab("") + 
  theme(legend.position="bottom")
@
\caption{\label{fig:timemodel-aes} Results of a model describing log evaluation time by evaluation outcome and plot type. Participants take less time to evaluate plots with a single aesthetic compared with more complicated plots. }
\end{figure}

We model log-transformed reaction time as a function of evaluation outcome (neither target identified, cluster or trend target identified, or both targets identified) and plot type. In order to remove the ``novelty" effect of an unfamiliar task, we also include an indicator variable for the first trial an individual completed \citep{Majumder:2014up}. A random effect for participant and dataset is included to account for the experimental design. Figure \ref{fig:timemodel-aes} displays the model results for each outcome of the lineup evaluation; simple plots (color, trend, shape) take less time to evaluate (across all conditions) than plots with more than one aesthetic. Additionally, participants who identified the cluster target took less time (in most cases) than participants identifying the trend target.  



\begin{figure}
<<timemodel-pars,echo=F, fig.width=8, fig.height=6, out.width='.8\\textwidth', dependson='results-setup'>>=

time.model2 <- lmer(log(as.numeric(trial.time))~ first.trial + plottype + simpleoutcome:trend.diff:cluster.diff:k  + (1|individualID) , data=modeldata)

coefs <- data.frame(exp(confint(time.model2, method="Wald")))[-(1:11),]
names(coefs) <- c("low", "high")
coefs$estimate <- exp(fixef(time.model2)[-(1:11)])
coefs$name <- names(fixef(time.model2))[-(1:11)]
ll <- ldply(strsplit(coefs$name, split=":"), function(x) x)
coefs$outcome <- gsub("simpleoutcome", "", ll$V1)
coefs$trend.diff <- gsub("trend\\.diff", "", ll$V2)
coefs$trend.diff <- factor(coefs$trend.diff, levels=c("easy", "medium", "hard"), labels=paste0("Trend:", c("Easy", "Medium", "Hard")))
coefs$cluster.diff <- gsub("cluster\\.diff", "", ll$V3)
coefs$cluster.diff <- factor(coefs$cluster.diff, levels=c("easy", "medium", "hard"), labels=paste0("Cluster:", c("Easy", "Medium", "Hard")))
coefs$k <- gsub("k", "", ll$V4)
coefs$simple <- coefs$outcome %in% c("both") - coefs$outcome%in%c("neither")
coefs$simple <- factor(coefs$simple)
levels(coefs$simple) <- c("Neither", "Cluster, Trend", "Both")

coefs$outcome <- factor(coefs$outcome, levels=c("neither", "cluster", "trend", "both"), labels=c("Neither Identified", "Cluster Identified", "Trend Identified", "Both Identified"))
coefs$pos <- as.numeric(factor(coefs$k)) + (as.numeric(factor(coefs$trend.diff))-2)/4

qplot(estimate, pos, data=subset(coefs, outcome!="Both Identified"), colour=trend.diff, size=I(4), shape=trend.diff) + theme_bw() + 
#  geom_vline(xintercept=1, color="grey") + 
  scale_colour_manual("Trend", values=c("#7bccc4", "#2b8cbe", "#084081")) +
  scale_shape_discrete("Trend") + 
  geom_segment(aes(x=low, xend=high, y=pos, yend=pos)) + 
  facet_grid(cluster.diff~outcome) + 
  scale_y_continuous(breaks=1:2, labels=unique(coefs$k), limits=c(0.5,2.5)) + 
  xlab("Additional time to evaluate each plot type (in seconds) given outcome") + ylab("K")

coefs2 <- data.frame(exp(confint(time.model2, method="Wald")))[c(1:11),]
names(coefs2) <- c("low", "high")
coefs2$estimate <- exp(fixef(time.model2)[c(1:11)])
coefs2$name <- names(fixef(time.model2))[c(1:11)]
coefs2$name <- coefs2$name %>% 
  str_replace("first\\.trialTRUE", "First Trial") %>%
  str_replace("plottype", "Plot Type: ") %>% 
  str_replace("color", "Color + ") %>% 
  str_replace("[sS]hape", "Shape + ") %>%
  str_replace("[tT]rend", "Trend + ") %>%
  str_replace("Ellipse", "Ellipse + ") %>%
  str_replace("Error", "Error + ") %>%
  str_replace("plain", "Plain") %>%
  str_replace("( \\+ )$", "") %>%
  str_replace(fixed("(Intercept)"), "Intercept")
coefs2$Interval <- sprintf("(%.2f, %.2f)", coefs2$low, coefs2$high)
names(coefs2)[3:5] <- c("Estimate", "Effect", "95% Confidence Interval")

print(xtable(coefs2[,c(4, 3, 5)], caption=c("Fitted values of plot type and first trial effects for a model describing log evaluation time as a function of plot type, first trial, and data generation parameters, with a random effect for participant. Additional parameters and intervals are shown in figure \\ref{fig:timemodel-pars}.", "Fixed effects for trial time model including data parameters."), label="tab:timemodel-pars", align=c('r', 'r', 'r', 'r'), digits=c(0, 0, 3, 0)), include.rownames=F, file="figure/timemodel-pars-fixef-table")
@
\caption{\label{fig:timemodel-pars} Results of a model describing log evaluation time by evaluation outcome and plot type. Participants take less time to evaluate plots with a single aesthetic compared with more complicated plots. }
\end{figure}
\input{figure/timemodel-pars-fixef-table}



In a second model, we fit log response time as a function of the plot type, first trial, and the interaction between the outcome and data-generation parameters $\sigma_C$, $\sigma_T$, and $K$. In order to model the task as designed, we have coded $\sigma_C$ and $\sigma_T$ according to difficulty level - easy, medium, and hard, rather than modeling the numerical parameters themselves; this allows us to describe the psychological task rather than the numerical task (and also simplifies the model slightly). Figure \ref{fig:timemodel-pars} shows the estimated difference in time as a function of difficulty level and trial outcome, and table \ref{tab:timemodel-pars} shows the additional fitted effects and 95\% intervals which are not shown graphically. 
% The increased variance for "Both" outcomes is a result of the relatively few trials in which participants identified multiple target plots (missing intervals are a result of this issue as well). 
The time to evaluate each plot increases slightly with trend difficulty and cluster difficulty (across trials), conditional on outcome, but the "medium" difficulty trials seem to be somewhat discordant in many cases; in some cases, time to evaluate increases and in others, it decreases. This may be due to a conflict between the trend and cluster target plots: when there is no clear signal numerically, evaluation time increases while participants waver between potential targets. 

%\comment{I removed "both" because it was distracting and missing a couple of CI's, but I'm not sure I'm happy with this now either. }
\subsection{Participant Confidence}

In addition to participant identification of target plots, we also asked participants to rate their confidence in their answer. 
Figure \ref{fig:conflevel} shows aggregate participant confidence rating as a function of trial outcome. 
Participants who did not identify either target plot were less likely to be ``extremely confident'' in their answer, while participants who identified either the trend or the cluster target correctly were highly confident that their answer was correct. 
Overall, though, participants seem to have some degree of confidence in their answer, regardless of whether the answer was correct.

<<participant-confidence,echo=F, fig.width=6.5, fig.height=4.25, out.width='.5\\linewidth', fig.cap="Participant confidence levels compared with trial results. \\label{fig:conflevel}">>=
conf.acc <- modeldata %>% 
  mutate(weight=1/nrow(modeldata), 
         outcome=factor(gsub("gini", "", outcome), 
                        levels=c("both", "cluster", "trend", "neither"))
         ) %>% 
  group_by(conf_level, outcome) %>% 
  summarize(pct.accuracy = sum(weight))
label.lines <- conf.acc %>% 
  filter(conf_level==5) %>% 
  transform(conf_level=5.25, 
            label=paste0("Target:\n",
                         gsub("(^|[[:space:]])([[:alpha:]])", "\\1\\U\\2", outcome, perl=TRUE))
            )
ggplot(data=conf.acc, aes(x=conf_level, y=pct.accuracy, group=outcome, color=outcome)) + 
  geom_line(size=2) + 
  scale_x_continuous("Participant Confidence", limits=c(-.25, 5.65), breaks=0:5) + 
  geom_text(data=label.lines, aes(label=label), hjust=.2, vjust=.5, color="black", show_guide=F, size=4) + 
  scale_color_brewer(guide="none", palette="Set1") + 
  ylab("Proportion of Trials") + 
  ggtitle("Participant Confidence and Trial Outcome") + 
  theme_bw()

@


\subsection{Participant Reasoning}\label{sec:sentiment}
As part of each trial, participants were asked to provide a short justification of their plot choice. Responses were categorized based on keywords such as ``line(ar)'', ``correlation'', ``group'', ``cluster'', ``clump'', as well as the presence of negation words (non, not, less, etc.). In addition to linear, nonlinear, and group sentiment, many responses focused on the presence of outliers or the amount of variability present in the chosen plot. 

\begin{figure}
% <<sentiment, echo=FALSE, fig.width=7, fig.height=7, out.width='.3\\textwidth', fig.show='hold'>>=
% lexicaldata <- modeldata
% lexicaldata$choice_reason <- tolower(lexicaldata$choice_reason)
% lexicaldata$choice_reason <- gsub("^_", "", lexicaldata$choice_reason)
% 
% words <- lexicaldata %>% group_by(plottype, simpleoutcome) %>% 
%   summarize(list = paste(choice_reason, collapse=" ")) %>% filter(simpleoutcome != "both", plottype %in% c("plain", "color", "trend", "colorEllipse"))
% 
% library(wordcloud)
% library(tm)
% for (i in 1:nrow(words)) {
% words.corpus <- Corpus(DataframeSource(data.frame(words$list[i])))
% words.corpus <- tm_map(words.corpus, removePunctuation)
% 
% tdm <- TermDocumentMatrix(words.corpus)
% m <- as.matrix(tdm)
% v <- sort(rowSums(m),decreasing=TRUE)
% d <- data.frame(word = names(v),freq=v)
% pal <- brewer.pal(9, "BuGn")
% pal <- pal[-(1:2)]
% #png(sprintf("wordcloud/wordcloud-%s-%s.png",words$plottype[i], words$simpleoutcome[i]), width=960,height=600)
% wordcloud(d$word,d$freq, scale=c(8,.3),min.freq=2,max.words=100, random.order=T, rot.per=.15, colors="black", vfont=c("sans serif","plain"))
% #dev.off()
% }
% @

\centering
\begin{subfigure}[t]{0.25\textwidth}
  \caption{Plain, neither target}
  \includegraphics[width=\textwidth]{figure/sentiment-1}
\end{subfigure}
\begin{subfigure}[t]{0.25\textwidth}
  \caption{Plain, cluster target}
  \includegraphics[width=\textwidth]{figure/sentiment-2}
\end{subfigure}
\begin{subfigure}[t]{0.25\textwidth}
  \caption{Plain, trend target}
  \includegraphics[width=\textwidth]{figure/sentiment-3}
\end{subfigure}

\begin{subfigure}[t]{0.25\textwidth}
  \caption{Trend, neither target}
  \includegraphics[width=\textwidth]{figure/sentiment-4}
\end{subfigure}
\begin{subfigure}[t]{0.25\textwidth}
  \caption{Trend, cluster target}
  \includegraphics[width=\textwidth]{figure/sentiment-5}
\end{subfigure}
\begin{subfigure}[t]{0.25\textwidth}
  \caption{Trend, trend target}
  \includegraphics[width=\textwidth]{figure/sentiment-6}
\end{subfigure}

\begin{subfigure}[t]{0.25\textwidth}
  \caption{Color, neither target}
  \includegraphics[width=\textwidth]{figure/sentiment-7}
\end{subfigure}
\begin{subfigure}[t]{0.25\textwidth}
  \caption{Color, cluster target}
  \includegraphics[width=\textwidth]{figure/sentiment-8}
\end{subfigure}
\begin{subfigure}[t]{0.25\textwidth}
  \caption{Color, trend target}
  \includegraphics[width=\textwidth]{figure/sentiment-9}
\end{subfigure}

\begin{subfigure}[t]{0.25\textwidth}
  \caption{Color + Ellipse, neither target}
  \includegraphics[width=\textwidth]{figure/sentiment-10}
\end{subfigure}
\begin{subfigure}[t]{0.25\textwidth}
  \caption{Color + Ellipse, cluster target}
  \includegraphics[width=\textwidth]{figure/sentiment-11}
\end{subfigure}
\begin{subfigure}[t]{0.25\textwidth}
  \caption{Color + Ellipse, trend target}
  \includegraphics[width=\textwidth]{figure/sentiment-12}
\end{subfigure}
\caption{\label{fig:wordles}Wordclouds of participants' reasoning by outcome for a selected number of plot types. Mostly, the reasoning and the choice of the target are highly associated. For the Ellipse + Color plot, participants were distracted from either target by an imbalance in the group/color distribution, as can be seen from the reasoning in the bottom left wordcloud.}
\end{figure}

\begin{figure}
<<lexical-analysis, echo=FALSE, fig.width=8, fig.height=6, out.width='.8\\linewidth'>>=
lexicaldata <- modeldata
lexicaldata$choice_reason <- tolower(lexicaldata$choice_reason)

get.reason <- function(x){
  negs <- "non|not|less|weak|least|no|lack|but|divergent"
  groups <- "group|cluster|spot|region|separat|clump|space|sets|gap|bunch|apart|connected|segregat|split|overlap|touch|area|tight|intersection|divided"
  linear <- "line|linear|correlation|trend|slant|angle|straight|slope"
  variability <- "outlier|spread|diffuse|random|scatter"
    reasons = data.frame(
      linear = str_detect(x, linear) & 
        !str_detect(x, negs) &
        !str_detect(x, groups),
      group = str_detect(x, groups) & 
        !str_detect(x, linear),
      nonlinear = str_detect(x, linear) & 
        str_detect(x, negs) & 
        !str_detect(x, groups),
      both = str_detect(x, groups) & 
        str_detect(x, linear) & 
        !str_detect(x, negs),
      outliers = str_detect(x, variability) & !str_detect(x, linear) & !str_detect(x, groups)
      )
    res <- rep("", length(x))
    res[rowSums(reasons)==0] <- "other"
    if(sum(rowSums(reasons)>1)>1){
      warning("Reasons are not mutually exclusive")
    }
    res[reasons$linear] <- "linear"
    res[reasons$nonlinear] <- "nonlinear"
    res[reasons$group] <- "group"
    res[reasons$both] <- "linear & group"
    res[reasons$outlier] <- "outlier"
    if(length(res)==1) return(unlist(res))
    return(res)
}

lexicaldata <- lexicaldata %>% 
  mutate(reason = get.reason(choice_reason))

lexicaldata$outcome <- factor(lexicaldata$outcome, levels=c("neither", "trend", "cluster", "both"), labels=c("Neither", "Trend", "Cluster", "Both"))
lexicaldata$reason <- factor(lexicaldata$reason, levels=c("group", "nonlinear", "outlier", "linear & group", "linear", "other"), labels=c("Group sentiment", "Non-linear sentiment", "Variability/Outlier sentiment", "Linear + Group sentiment", "Linear sentiment", "Other"))

qplot(data=lexicaldata, x=outcome, fill=reason, geom="histogram", position="dodge") + facet_wrap(~reason) + 
  scale_fill_brewer(guide="none", palette="Set1") + 
  ylab("# Responses") + 
  xlab("Outcome") + 
  ggtitle("Sentiment Expressed in Participant Explanations, by Trial Outcome") + 
  theme_bw()

@
\caption[Lexical analysis of participant reasoning]{Lexical analysis of participants' justification of plot selection. Group sentiment in the reasoning is highly associated with selection of the cluster target plot; linear sentiment is highly associated with selection of the trend target plot.}\label{fig:lexicalanalysis}
\end{figure}

\newtext{The results of this analysis, shown in figure \ref{fig:lexicalanalysis}, indicate that for the most part participants were making decisions based on the criteria we manipulated; rather than alternate visual cues such as group size, which were present in only a few responses. }


\section{Discussion and Conclusions}\label{sec:Conclusion}
\newtext{
Taken together, the results presented suggest that plot aesthetics influence the perception of the dominant effect in the displayed data. This effect is not simply additive (otherwise, the two conflicting aesthetic conditions would result in similarly neutral effects); rather, the effect is consistent with layering of gestalt perceptual heuristics. Plot layers which add additional heuristics show larger effects than plot layers which duplicate heuristics which are already in play. For example, adding ellipses to a plot which has color aesthetics increases group recognition by recruiting the closure heuristic in addition to the point similarity heuristic recruited by color; adding shape to a plot which has color aesthetics may increases group recognition slightly, but does not add additional gestalt heuristics (though point similarity is emphasized through two different mechanisms). 

In order to explicitly rank aesthetics given this nonadditive mechanism, it would be necessary to test ellipse and error band aesthetics alone; in this study, we have only examined those aesthetics in combination with color and regression line plot layers, as the bounding aesthetics are seldom seen alone. 

While further exploration of these effects is necessary to control for the effects of group size as well as to explore the gestalt heuristics applicable to other types of plots, these results demonstrate the importance of carefully constructing graphs in order to consistently convey the most important aspects of the displayed data. 
}
\bibliographystyle{asa}
\bibliography{references}
\newpage
\begin{appendix}
\section{Simulation Studies of Parameter Space}\label{app:parametersimulation}
\subsection{Distribution of Test Statistics}

Simulating lineup data sets, we can compare test statistics measuring trend strength, cluster strength, and cluster size inequality for the null plots and target plots. These distributions allow us to objectively assess the difficulty of detecting the target datasets computationally (without relying on human perception). This approach is similar to that taken in \citet{niladri:2014}.

The trend strength is assessed numerically using the coefficient of determination, $R^2$, which is calculated as in equation \ref{eq:linearMeasure}. 

The cluster strength is assessed by comparing the percent of variation in x and y accounted for by the clusters to the total variation, as in equation \ref{eq:clusterMeasure}.


\begin{figure}[h]
\centering
<<null-distribution, echo=FALSE, cache=T, fig.width=8, fig.height=3>>=
source("../../Code/MixtureLineups.R")
sT = 0.25
sC = 0.20
N = 45
K = 3
M = 1000

if (file.exists("./figure/nulldist.Rdata")) {
  load("./figure/nulldist.Rdata")
} else {
#   nulldist<- function(N, sT=0.25, sC=0.2) {
#     nulls <- data.frame(t(replicate(N, {
#       lp <- data.frame(t(replicate(18, {
#         mix = mixture.sim(lambda=0.5, K=3, N=45, sd.cluster=sC, sd.trend=sT)
#         reg <- lm(y~x, data=mix)
#         
#   c(fline=summary(reg)$r.squared, fgroup=cluster(mix))
#   })))
#     c(fline=max(lp$fline), fgroup=max(lp$fgroup))
#   })))
#   
#   trends <- replicate(10, {
#     mix = mixture.sim(lambda=0, K=3, N=45, sd.cluster=sC, sd.trend=sT)
#     reg <- lm(y~x, data=mix)
#     c(fline=summary(reg)$r.squared)
#   })
#   
#   clusters <- replicate(10, {
#     mix = mixture.sim(lambda=1, K=3, N=45, sd.cluster=sC, sd.trend=sT)
#     clust <- lm(y~factor(group) + 0, data=mix)
#     res <- summary(aov(clust))
#     c(fgroup=cluster(mix))
#   })
#   
#   list(nulls=nulls, trends=trends, clusters=clusters)
# }
# 
# res <- nulldist(N=N, sC=sC, sT=sT)
  library(compiler)
  tmp <- function(M=1000, N=45, K=3, sT=0.3, sC=0.25) {
    data.frame(
      t(
        replicate(M, 
                  {
                    input.pars <- list(N=N, K=K, sd.trend=sT, sd.cluster=sC)
                    c(unlist(input.pars), eval.data(gen.data(input.pars)))
                    }
                  )
        )
      )
    }
  nulldist <- cmpfun(tmp)
  
  res <- nulldist(M=M, N=45, K=3, sT=sT, sC=sC)
  
  save(res, file="./figure/nulldist.Rdata")
}

# require(ggplot2)
# qplot(fline, data=res$nulls, binwidth=0.02, fill=I("gray70"), color=I("gray20")) + geom_vline(aes(xintercept=res$trends), color="black") + theme_bw() + xlab("Max(18) Distribution of Cluster Measure under Null Model")
# ggsave("figure/fline.pdf", width=8, height=4)
# qplot(fgroup, data=res$nulls, binwidth=0.01, fill=I("gray70"), color=I("gray20")) + geom_vline(aes(xintercept=res$clusters), color="black") + theme_bw() + xlab("Max(18) Distribution of Trend Measure under Null Model")
# ggsave("figure/fgroup.pdf", width=8, height=4)

longres <- melt(res, id.vars=1:4, variable.name="type", value.name = "value")
longres$dist <- c("Data", "Most Extreme of\n18 Null Dists")[1+grepl("null", longres$type)]
longres$type <- gsub("null.", "", longres$type, fixed=T)
longres$Statistic <- longres$type
longres$Statistic[longres$type=="cluster"] <- "Cluster Measure"
longres$Statistic[longres$type=="line"] <- "R^2"
longres$Statistic[longres$type=="gini"] <- "Gini Impurity"
longres$Statistic <- factor(longres$Statistic, levels=c("R^2", "Cluster Measure", "Gini Impurity"))

qplot(data=longres, x=value, y=..density.., stat="density", color=dist, fill=dist, geom="area", alpha=I(.5), 
      main=expression(paste("Simulation Results " , group("(", list(K==3, sigma[T]==.25, sigma[C]==.2), ")"))), 
      xlab="Simulated Distribution of Test Statistic", 
      ylab="Density", 
      position="identity") + 
  facet_grid(.~Statistic, scales="free", labeller=label_both) + 
  scale_color_manual("Distribution", values=c("black",  "gray")) + 
  scale_fill_manual("Distribution", values=c("transparent", "gray")) +  
  theme_bw()
@
\caption{\label{fig:targetsignal}Density of test statistics measuring trend strength, cluster strength, and cluster inequality for target distributions and null plots. }
\end{figure}

Figure~\ref{fig:targetsignal} show computed densities of the maximum null distribution measure compared with the measure in the signal plot. There is some overlap in the distribution of $R^2$ for the null plots compared with the target plot displaying data drawn from $M_T$. We have two measures comparing data drawn from $M_C$ and $M_0$; the cluster measure examines the variance in $x$ and $y$ described by the cluster center; the gini coefficient examines the inequality in group sizes. These simulations indicate that it may be possible to differentiate $M_C$ based on two different features in clustered data. In future experiments, it may be beneficial to control cluster size more tightly to remove this additional feature. 

The distribution of the cluster statistic values are more easily separated from the null plots than the distribution of the line statistic, indicating that $\sigma_C = 0.20$ is producing target plots that are a bit easier to spot than trend targets with a parameter value of $\sigma_T = 0.25$, however, the inequality of group sizes may distract participants from the intended target signal of cluster cohesion.


\subsection{Full Parameter Space Simulation Study}
Using 1000 simulations for each of the 98 combinations of parameters ($K=\{3,5\}$, $\sigma_C=\{.1, .15, .2, .25, .3, .35, .4\}$, $\sigma_T=\{.2, .25, .3, .35, .4, .45, .5\}$), we explored the effect of parameter value on the distribution of summary statistics describing the line strength ($R^2$) and cluster strength for null and target plots. 

Figures \ref{fig:simulationLineIntervals} and \ref{fig:simulationClusterIntervals} show the 25th and 75th percentiles of the distribution of $R^2$ and cluster strength summary statistics for each set of parameter values. These plots guided our evaluation of ``easy", ``medium" and ``hard" parameter values for line and cluster tasks. 


Additionally, we note that there is an interaction between $\sigma_C$ and $\sigma_T$: the distinction between target and null on a fixed setting of clustering becomes increasingly difficult as the standard deviation for the linear trend is increased, and vice versa. There may additionally be a three-way interaction between $\sigma_C, \sigma_T$, and $K$: the size of the blue intervals (bottom figure) changes in size between different levels of $K$, it changes for different levels of $\sigma_C$ and $\sigma_T$. These interactions suggest that in order to examine differences in aesthetics, we must block by parameter settings (this can be accomplished through blocking by dataset). Each dataset is non-deterministic, because we have a random process generating from different parameter settings, not a deterministic run setting as in an engineering setting. It is thus important to use replicates of each parameter setting to ensure that we can separate data-level effects from parameter-level effects. 

<<simulationparameters,echo=F,include=F, fig.width=10, fig.height=6.5, out.width='.8\\linewidth'>>=
load("../../Data/SimulationDatasetCriteriaTurk16.Rdata")

dataset.criteria$ParameterSet <- with(dataset.criteria, sprintf("sdT%.2f-sdC%.2f", sd.trend, sd.cluster))
dataset.criteria$ParameterSet[dataset.criteria$type=="cluster"] <- with(dataset.criteria[dataset.criteria$type=="cluster",], sprintf("sdC%.2f-sdT%.2f", sd.cluster, sd.trend))

dataset.criteria$lsc <- paste("sigma[C]: ", round(dataset.criteria$sd.cluster, 2))
dataset.criteria$lst <- paste("sigma[T]: ", round(dataset.criteria$sd.trend, 2))
dataset.criteria$lK <- paste("K: ", dataset.criteria$K)
qplot(data=subset(dataset.criteria, type=="line"), x=LB, xend=UB, y=sd.cluster, yend=sd.cluster, color=dist, geom="segment") +
  geom_point(aes(x=LB, y=sd.cluster, color=dist))  + 
  geom_point(aes(x=UB, y=sd.cluster, color=dist)) + 
  facet_grid(lst~lK, scales="free", labeller="label_parsed")  + theme_bw() + 
  scale_color_brewer("Distribution",palette="Set1") + theme(legend.position="bottom") + xlab("Interquartile intervals of Max (18) null distribution (blue) \nand target distribution (red) of linearity measured in R squared.") + ylab(expression("Cluster variability":sigma[C]))

qplot(data=subset(dataset.criteria, type=="cluster"), x=LB, xend=UB, y=sd.trend, yend=sd.trend, color=dist, geom="segment") +
  geom_point(aes(x=LB, y=sd.trend, color=dist))  + 
  geom_point(aes(x=UB, y=sd.trend, color=dist)) + 
  facet_grid(lsc~lK, scales="free", labeller="label_parsed")  + theme_bw() + 
  scale_color_brewer("Distribution", palette="Set1") + theme(legend.position="bottom") + xlab("Interquartile intervals of Max (18) null distribution (blue) \nand target distribution (red) of amount of clustering.") + ylab(expression( "Variability along the trend":sigma[T]))

tmp <- subset(dataset.criteria, type=="gini")
tmp$dist <- gsub("Max", "Min", tmp$dist)
qplot(data=tmp, x=LB, xend=UB, y=sd.trend, yend=sd.trend, color=dist, geom="segment") +
  geom_point(aes(x=LB, y=sd.trend, color=dist))  + 
  geom_point(aes(x=UB, y=sd.trend, color=dist)) + 
  facet_grid(lsc~lK, scales="free", labeller="label_parsed")  + theme_bw() + 
  scale_color_brewer("Distribution", palette="Set1") + theme(legend.position="bottom") + xlab("Interquartile intervals of Min (18) null distribution (blue) \nand target distribution (red) of Gini Impurity.") + ylab(expression( "Variability along the trend":sigma[T]))
@

\begin{figure}\centering
\includegraphics[width=.8\linewidth]{figure/simulationparameters-1}
\caption{Simulated interquartile range of $R^2$ values for target and null data distributions. \label{fig:simulationLineIntervals}}
\end{figure}

\begin{figure}\centering
\includegraphics[width=.8\linewidth]{figure/simulationparameters-2}
\caption{Simulated interquartile range of cluster cohesion statistic values for target and null data distributions. \label{fig:simulationClusterIntervals}}
\end{figure}

Additionally, after the experiment was complete, we examined the distribution of group size (as measured by gini impurity) to establish whether there were any systematic differences in group size inequality between data generated from $M_0$ (null data) and data generated from $M_C$ (cluster data). Figure \ref{fig:simulationGiniIntervals} demonstrates that the cluster plots have significantly lower group size differences than null plots at all parameter combinations. It is therefore possible that some participants will identify extraordinarily unequal group sizes present in null plots as significantly different from the other lineup plots, ignoring any cluster signal. Future studies should more tightly control group size in order to reduce this effect. 

\begin{figure}\centering
\includegraphics[width=.8\linewidth]{figure/simulationparameters-3}
\caption{Simulated interquartile range of group size inequality statistic values for cluster and null data distributions. \label{fig:simulationGiniIntervals}}
\end{figure}

%' 
%' \section{Graphical Exploration}
%' 
%' % \comment{The graphical exploration is very much not straightforward - let's move it to the back and get the results from the models. Accuracy first: line, group, faceoff. Time and Confidence level second. }
%' 
%' Figure \ref{fig:accuracy-plottype} shows aggregate accuracy rates for each plot aesthetic combination. It is again apparent that the cluster targets were overall more likely to be identified than line targets across all aesthetic combinations, however, it is also evident that plot aesthetics influence the identified target.
%' 
%' <<plot-accuracy-rate, echo=F, fig.width=10, fig.height=5, out.width='.8\\linewidth', fig.cap="Proportion of trials identifying each target for each plot type (across parameter settings).\\label{fig:accuracy-plottype}", dependson='results-setup'>>=
%' 
%' plottype.accuracy <- modeldata.long %>% 
%'   group_by(plottype, answer.type) %>% 
%'   summarize(accuracy=mean(correct)) %>%
%'   ungroup() %>%
%'   group_by(plottype) %>%
%'   transform(total.acc = sum(accuracy))
%' plottype.accuracy$plottype <- factor(plottype.accuracy$plottype, levels=c("Trend + Error", "Trend", "Plain", "Shape", "Color", "Color + Shape", "Color + Trend", "Color + Shape + Ellipse", "Color + Ellipse", "Color + Ellipse + Trend + Error"))
%' plottype.accuracy$answer.type <- factor(plottype.accuracy$answer.type, levels=c("neither", "trend", "cluster"))
%' qplot(x=plottype, y=accuracy, fill=answer.type, 
%'       geom="bar", data=plottype.accuracy, position="stack", stat="identity") +
%'   scale_fill_brewer("Target Identified", palette="Set1") + 
%'   theme_bw() + 
%'   xlab("Plot Aesthetic") + 
%'   ylab("Proportion of Trials") + 
%'   coord_flip()
%' @
%' 
%' 
%' 
%' <<speedaccuracy1,echo=F, fig.width=8, fig.height=4, out.width='.9\\linewidth', fig.cap="Accuracy (identifying either target plot) compared with mean trial time, by plot aesthetic.\\label{fig:speedaccuracyaes}", dependson='results-setup'>>=
%' time.accuracy <- modeldata %>% 
%'   group_by(individualID) %>%
%'   transform(trial.num=order(start_time)) %>%
%'   filter(trial.num>1 & as.numeric(trial.time)<60*3)  %>%
%'   group_by(plottype, dataset, k, cluster.diff2, trend.diff2) %>% 
%'   summarise(mean.trial.time = mean(trial.time), accuracy = 1-mean(neither.correct)) %>% 
%'   arrange(mean.trial.time) %>% 
%'   melt(id.var=c("plottype", "dataset", "k", "cluster.diff2",  "trend.diff2", "mean.trial.time")) 
%' time.accuracy$plottype <- time.accuracy$plottype %>%
%'   str_replace("color", "Color + ") %>% 
%'   str_replace("[sS]hape", "Shape + ") %>%
%'   str_replace("[tT]rend", "Trend + ") %>%
%'   str_replace("Ellipse", "Ellipse + ") %>%
%'   str_replace("Error", "Error + ") %>%
%'   str_replace("plain", "Plain") %>%
%'   str_replace("( \\+ )$", "") %>% 
%'   factor(levels=c("Plain", "Color", "Shape", "Trend", "Trend + Error", 
%'                   "Color + Shape", "Color + Ellipse", "Color + Trend", 
%'                   "Color + Shape + Ellipse", "Color + Ellipse + Trend + Error"),
%'          labels=c("Plain", "Color", "Shape", "Trend", "Trend + Error", 
%'                   "Color + Shape", "Color + Ellipse", "Color + Trend", 
%'                   "Color + Shape\n + Ellipse", "Color + Ellipse\n + Trend + Error"))
%' 
%' mean.time <- time.accuracy %>% group_by(plottype) %>% summarise(trial.time=sprintf("Avg. Time:\n%.1f s", as.numeric(mean(mean.trial.time))), mean.trial.time=as.numeric(mean(mean.trial.time)))
%' 
%' 
%' qplot(data=time.accuracy, x=as.numeric(mean.trial.time), y=value, color=plottype, shape=I(1)) + 
%'   geom_smooth(span=1.5, aes(ymax=pmin(1, ..ymax..), group=plottype), color="black") + 
%'   xlab("Mean Time to Trial Completion by Plot\n(excluding each participant's 1st trial)") + 
%'   ylab("Accuracy") + 
%'   scale_color_discrete("Plot Aesthetic", guide="none") + 
%'   geom_text(data=mean.time, aes(x=mean.trial.time, y=0, label=trial.time), inherit.aes=F, vjust=0, hjust=.25, show_guide=F) + 
%'   facet_wrap(~plottype, nrow=2) + theme_bw()
%' @
%' 
%' 
%' <<speedaccuracy2,echo=F, fig.width=8, fig.height=6, out.width='.75\\linewidth',, fig.cap="Accuracy (identifying either target plot) compared with mean trial time, by parameter settings.\\label{fig:speedaccuracypars}">>=
%' 
%' mean.time <- time.accuracy %>% group_by(trend.diff2, cluster.diff2) %>% summarise(trial.time=sprintf("Avg. Time:\n%.1f s", as.numeric(mean(mean.trial.time))), mean.trial.time=as.numeric(mean(mean.trial.time)))
%' 
%' time.accuracy$plottype <- factor(time.accuracy$plottype,
%'                                  levels=c("Plain", "Color", "Shape", "Trend", "Trend + Error", 
%'                                           "Color + Shape", "Color + Ellipse", "Color + Trend", 
%'                                           "Color + Shape\n + Ellipse", "Color + Ellipse\n + Trend + Error"),
%'                                  labels=c("Plain", "Color", "Shape", "Trend", "Trend + Error", 
%'                                           "Color + Shape", "Color + Ellipse", "Color + Trend", 
%'                                           "Color + Shape + Ellipse", "Color + Ellipse + Trend + Error"))
%' 
%' qplot(data=time.accuracy, x=as.numeric(mean.trial.time), y=value, color=plottype, shape=k) + 
%'   geom_smooth(span=1, aes(group=k, linetype=k), se=F, color="black") + 
%'   scale_linetype_discrete("# Clusters (K)") + 
%'   xlab("Mean Time to Trial Completion by Plot\n(excluding each participant's 1st trial)") + 
%'   ylab("Accuracy") + 
%'   scale_color_discrete("Aesthetic Emphasis") + 
%'   scale_shape_manual("# Clusters (K)", values=c(16, 1)) + 
%'   geom_text(data=mean.time, aes(x=mean.trial.time, y=0, label=trial.time), inherit.aes=F, vjust=0, show_guide=F) + 
%'   facet_grid(trend.diff2~cluster.diff2) + theme_bw()
%' @

\section{Model Results}

\input{figure/linear-fixef-table}
\input{figure/group-fixef-table}

\end{appendix}
\end{document}